{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # calculations with arrays\n",
    "import pandas as pd # user-friendly DataFrames for data representation\n",
    "import sklearn # machine learning algorithms\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "import xgboost as xgboost\n",
    "import matplotlib.pyplot as plt # import plot functions\n",
    "# necessary to plot in jupyter notebook:\n",
    "%matplotlib inline\n",
    "import seaborn as sns # make plots beautiful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Classification and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2998</td>\n",
       "      <td>19</td>\n",
       "      <td>317</td>\n",
       "      <td>131</td>\n",
       "      <td>336</td>\n",
       "      <td>278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2998</td>\n",
       "      <td>28</td>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>301</td>\n",
       "      <td>259</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  day  team1  team2  score1  score2 target\n",
       "0  2998   19    317    131     336     278   True\n",
       "1  2998   28     61     29     301     259   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3021</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2\n",
       "0   0  3021    363    161\n",
       "1   1  3021    286      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "train_team1 = pd.DataFrame(enc.fit_transform(train[['team1']]))\n",
    "train_team2 = pd.DataFrame(enc.transform(train[['team2']]))\n",
    "train_teams = pd.concat([train_team1, train_team2], axis=1)\n",
    "\n",
    "test_team1 = pd.DataFrame(enc.transform(test[['team1']]))\n",
    "test_team2 = pd.DataFrame(enc.transform(test[['team2']]))\n",
    "test_teams = pd.concat([test_team1, test_team2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125207, 706)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_teams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([train[['year']], train_teams], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_submission = pd.concat([test[['year']], test_teams], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125207, 707)\n",
      "162\n",
      "1\n",
      "113\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "print X_test_submission.shape\n",
    "for c in test.team2.unique():\n",
    "    if(c not in train.team1.unique()):\n",
    "        print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[X['year'] <= 3014]\n",
    "y_train = train[train['year'] <= 3014].target\n",
    "X_test = X[X['year'] > 3014]\n",
    "y_test = train[train['year'] > 3014].target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = alg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.193379599483086"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00099407, -0.05548319, -0.06027442])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.coef_[0, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент при years мал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Взвешенная сумма алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = linear_model.LogisticRegression(C = 0.8)\n",
    "\n",
    "param = {}\n",
    "param['max_depth'] = 25\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.1\n",
    "\n",
    "numround = 594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = sklearn.cross_validation.train_test_split(X, train.target,  \n",
    "                                                                                     test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.690109\teval-logloss:0.690788\n",
      "[1]\ttrain-logloss:0.687565\teval-logloss:0.688872\n",
      "[2]\ttrain-logloss:0.685276\teval-logloss:0.687193\n",
      "[3]\ttrain-logloss:0.683182\teval-logloss:0.685592\n",
      "[4]\ttrain-logloss:0.681168\teval-logloss:0.684320\n",
      "[5]\ttrain-logloss:0.679537\teval-logloss:0.683097\n",
      "[6]\ttrain-logloss:0.677633\teval-logloss:0.681914\n",
      "[7]\ttrain-logloss:0.676035\teval-logloss:0.680802\n",
      "[8]\ttrain-logloss:0.674310\teval-logloss:0.679799\n",
      "[9]\ttrain-logloss:0.672684\teval-logloss:0.678659\n",
      "[10]\ttrain-logloss:0.671157\teval-logloss:0.677744\n",
      "[11]\ttrain-logloss:0.669748\teval-logloss:0.676769\n",
      "[12]\ttrain-logloss:0.668295\teval-logloss:0.675906\n",
      "[13]\ttrain-logloss:0.666839\teval-logloss:0.675097\n",
      "[14]\ttrain-logloss:0.665537\teval-logloss:0.674322\n",
      "[15]\ttrain-logloss:0.664031\teval-logloss:0.673402\n",
      "[16]\ttrain-logloss:0.662689\teval-logloss:0.672632\n",
      "[17]\ttrain-logloss:0.661477\teval-logloss:0.671802\n",
      "[18]\ttrain-logloss:0.660071\teval-logloss:0.670948\n",
      "[19]\ttrain-logloss:0.658700\teval-logloss:0.670130\n",
      "[20]\ttrain-logloss:0.657412\teval-logloss:0.669439\n",
      "[21]\ttrain-logloss:0.656155\teval-logloss:0.668791\n",
      "[22]\ttrain-logloss:0.655072\teval-logloss:0.668240\n",
      "[23]\ttrain-logloss:0.653961\teval-logloss:0.667634\n",
      "[24]\ttrain-logloss:0.652756\teval-logloss:0.666897\n",
      "[25]\ttrain-logloss:0.651508\teval-logloss:0.666215\n",
      "[26]\ttrain-logloss:0.650327\teval-logloss:0.665512\n",
      "[27]\ttrain-logloss:0.649099\teval-logloss:0.664815\n",
      "[28]\ttrain-logloss:0.648101\teval-logloss:0.664252\n",
      "[29]\ttrain-logloss:0.646953\teval-logloss:0.663555\n",
      "[30]\ttrain-logloss:0.645985\teval-logloss:0.662888\n",
      "[31]\ttrain-logloss:0.644924\teval-logloss:0.662266\n",
      "[32]\ttrain-logloss:0.643704\teval-logloss:0.661764\n",
      "[33]\ttrain-logloss:0.642635\teval-logloss:0.661156\n",
      "[34]\ttrain-logloss:0.641641\teval-logloss:0.660708\n",
      "[35]\ttrain-logloss:0.640473\teval-logloss:0.660109\n",
      "[36]\ttrain-logloss:0.639531\teval-logloss:0.659581\n",
      "[37]\ttrain-logloss:0.638466\teval-logloss:0.658974\n",
      "[38]\ttrain-logloss:0.637624\teval-logloss:0.658437\n",
      "[39]\ttrain-logloss:0.636541\teval-logloss:0.657757\n",
      "[40]\ttrain-logloss:0.635498\teval-logloss:0.657354\n",
      "[41]\ttrain-logloss:0.634558\teval-logloss:0.656880\n",
      "[42]\ttrain-logloss:0.633467\teval-logloss:0.656232\n",
      "[43]\ttrain-logloss:0.632511\teval-logloss:0.655708\n",
      "[44]\ttrain-logloss:0.631576\teval-logloss:0.655280\n",
      "[45]\ttrain-logloss:0.630741\teval-logloss:0.654769\n",
      "[46]\ttrain-logloss:0.629614\teval-logloss:0.654224\n",
      "[47]\ttrain-logloss:0.628560\teval-logloss:0.653652\n",
      "[48]\ttrain-logloss:0.627648\teval-logloss:0.653222\n",
      "[49]\ttrain-logloss:0.626749\teval-logloss:0.652668\n",
      "[50]\ttrain-logloss:0.625890\teval-logloss:0.652247\n",
      "[51]\ttrain-logloss:0.624877\teval-logloss:0.651672\n",
      "[52]\ttrain-logloss:0.624049\teval-logloss:0.651260\n",
      "[53]\ttrain-logloss:0.623167\teval-logloss:0.650753\n",
      "[54]\ttrain-logloss:0.622444\teval-logloss:0.650346\n",
      "[55]\ttrain-logloss:0.621490\teval-logloss:0.649998\n",
      "[56]\ttrain-logloss:0.620599\teval-logloss:0.649535\n",
      "[57]\ttrain-logloss:0.619675\teval-logloss:0.648967\n",
      "[58]\ttrain-logloss:0.618973\teval-logloss:0.648612\n",
      "[59]\ttrain-logloss:0.617914\teval-logloss:0.648106\n",
      "[60]\ttrain-logloss:0.616984\teval-logloss:0.647706\n",
      "[61]\ttrain-logloss:0.616204\teval-logloss:0.647251\n",
      "[62]\ttrain-logloss:0.615284\teval-logloss:0.646888\n",
      "[63]\ttrain-logloss:0.614445\teval-logloss:0.646428\n",
      "[64]\ttrain-logloss:0.613628\teval-logloss:0.646012\n",
      "[65]\ttrain-logloss:0.612844\teval-logloss:0.645601\n",
      "[66]\ttrain-logloss:0.611922\teval-logloss:0.645026\n",
      "[67]\ttrain-logloss:0.611120\teval-logloss:0.644675\n",
      "[68]\ttrain-logloss:0.610299\teval-logloss:0.644189\n",
      "[69]\ttrain-logloss:0.609457\teval-logloss:0.643766\n",
      "[70]\ttrain-logloss:0.608670\teval-logloss:0.643393\n",
      "[71]\ttrain-logloss:0.607832\teval-logloss:0.642940\n",
      "[72]\ttrain-logloss:0.607069\teval-logloss:0.642449\n",
      "[73]\ttrain-logloss:0.606244\teval-logloss:0.642041\n",
      "[74]\ttrain-logloss:0.605554\teval-logloss:0.641616\n",
      "[75]\ttrain-logloss:0.604801\teval-logloss:0.641327\n",
      "[76]\ttrain-logloss:0.604107\teval-logloss:0.640970\n",
      "[77]\ttrain-logloss:0.603181\teval-logloss:0.640583\n",
      "[78]\ttrain-logloss:0.602394\teval-logloss:0.640172\n",
      "[79]\ttrain-logloss:0.601587\teval-logloss:0.639797\n",
      "[80]\ttrain-logloss:0.600699\teval-logloss:0.639477\n",
      "[81]\ttrain-logloss:0.599985\teval-logloss:0.639190\n",
      "[82]\ttrain-logloss:0.599303\teval-logloss:0.638919\n",
      "[83]\ttrain-logloss:0.598492\teval-logloss:0.638531\n",
      "[84]\ttrain-logloss:0.597728\teval-logloss:0.638192\n",
      "[85]\ttrain-logloss:0.597090\teval-logloss:0.637896\n",
      "[86]\ttrain-logloss:0.596297\teval-logloss:0.637542\n",
      "[87]\ttrain-logloss:0.595512\teval-logloss:0.637071\n",
      "[88]\ttrain-logloss:0.594917\teval-logloss:0.636823\n",
      "[89]\ttrain-logloss:0.594288\teval-logloss:0.636596\n",
      "[90]\ttrain-logloss:0.593497\teval-logloss:0.636294\n",
      "[91]\ttrain-logloss:0.592792\teval-logloss:0.635917\n",
      "[92]\ttrain-logloss:0.592095\teval-logloss:0.635615\n",
      "[93]\ttrain-logloss:0.591464\teval-logloss:0.635394\n",
      "[94]\ttrain-logloss:0.590687\teval-logloss:0.635135\n",
      "[95]\ttrain-logloss:0.590074\teval-logloss:0.634949\n",
      "[96]\ttrain-logloss:0.589438\teval-logloss:0.634576\n",
      "[97]\ttrain-logloss:0.588780\teval-logloss:0.634127\n",
      "[98]\ttrain-logloss:0.587980\teval-logloss:0.633810\n",
      "[99]\ttrain-logloss:0.587299\teval-logloss:0.633482\n",
      "[100]\ttrain-logloss:0.586745\teval-logloss:0.633373\n",
      "[101]\ttrain-logloss:0.585980\teval-logloss:0.633060\n",
      "[102]\ttrain-logloss:0.585333\teval-logloss:0.632755\n",
      "[103]\ttrain-logloss:0.584679\teval-logloss:0.632536\n",
      "[104]\ttrain-logloss:0.584019\teval-logloss:0.632242\n",
      "[105]\ttrain-logloss:0.583359\teval-logloss:0.631930\n",
      "[106]\ttrain-logloss:0.582600\teval-logloss:0.631580\n",
      "[107]\ttrain-logloss:0.582025\teval-logloss:0.631270\n",
      "[108]\ttrain-logloss:0.581476\teval-logloss:0.631074\n",
      "[109]\ttrain-logloss:0.580851\teval-logloss:0.630828\n",
      "[110]\ttrain-logloss:0.580245\teval-logloss:0.630653\n",
      "[111]\ttrain-logloss:0.579599\teval-logloss:0.630460\n",
      "[112]\ttrain-logloss:0.578975\teval-logloss:0.630155\n",
      "[113]\ttrain-logloss:0.578436\teval-logloss:0.629920\n",
      "[114]\ttrain-logloss:0.577778\teval-logloss:0.629662\n",
      "[115]\ttrain-logloss:0.577171\teval-logloss:0.629461\n",
      "[116]\ttrain-logloss:0.576480\teval-logloss:0.629198\n",
      "[117]\ttrain-logloss:0.576005\teval-logloss:0.628998\n",
      "[118]\ttrain-logloss:0.575478\teval-logloss:0.628783\n",
      "[119]\ttrain-logloss:0.574860\teval-logloss:0.628527\n",
      "[120]\ttrain-logloss:0.574271\teval-logloss:0.628192\n",
      "[121]\ttrain-logloss:0.573697\teval-logloss:0.628011\n",
      "[122]\ttrain-logloss:0.573117\teval-logloss:0.627757\n",
      "[123]\ttrain-logloss:0.572574\teval-logloss:0.627568\n",
      "[124]\ttrain-logloss:0.571943\teval-logloss:0.627256\n",
      "[125]\ttrain-logloss:0.571350\teval-logloss:0.627101\n",
      "[126]\ttrain-logloss:0.570695\teval-logloss:0.626868\n",
      "[127]\ttrain-logloss:0.569996\teval-logloss:0.626687\n",
      "[128]\ttrain-logloss:0.569381\teval-logloss:0.626466\n",
      "[129]\ttrain-logloss:0.568749\teval-logloss:0.626189\n",
      "[130]\ttrain-logloss:0.568148\teval-logloss:0.626016\n",
      "[131]\ttrain-logloss:0.567472\teval-logloss:0.625710\n",
      "[132]\ttrain-logloss:0.566825\teval-logloss:0.625365\n",
      "[133]\ttrain-logloss:0.566381\teval-logloss:0.625217\n",
      "[134]\ttrain-logloss:0.565841\teval-logloss:0.625033\n",
      "[135]\ttrain-logloss:0.565306\teval-logloss:0.624820\n",
      "[136]\ttrain-logloss:0.564728\teval-logloss:0.624603\n",
      "[137]\ttrain-logloss:0.564053\teval-logloss:0.624290\n",
      "[138]\ttrain-logloss:0.563523\teval-logloss:0.624100\n",
      "[139]\ttrain-logloss:0.562821\teval-logloss:0.623917\n",
      "[140]\ttrain-logloss:0.562331\teval-logloss:0.623758\n",
      "[141]\ttrain-logloss:0.561627\teval-logloss:0.623451\n",
      "[142]\ttrain-logloss:0.561067\teval-logloss:0.623333\n",
      "[143]\ttrain-logloss:0.560511\teval-logloss:0.623151\n",
      "[144]\ttrain-logloss:0.559985\teval-logloss:0.623008\n",
      "[145]\ttrain-logloss:0.559388\teval-logloss:0.622859\n",
      "[146]\ttrain-logloss:0.558827\teval-logloss:0.622625\n",
      "[147]\ttrain-logloss:0.558302\teval-logloss:0.622495\n",
      "[148]\ttrain-logloss:0.557662\teval-logloss:0.622266\n",
      "[149]\ttrain-logloss:0.557133\teval-logloss:0.622084\n",
      "[150]\ttrain-logloss:0.556567\teval-logloss:0.621935\n",
      "[151]\ttrain-logloss:0.556044\teval-logloss:0.621795\n",
      "[152]\ttrain-logloss:0.555557\teval-logloss:0.621658\n",
      "[153]\ttrain-logloss:0.555093\teval-logloss:0.621434\n",
      "[154]\ttrain-logloss:0.554672\teval-logloss:0.621273\n",
      "[155]\ttrain-logloss:0.554133\teval-logloss:0.621051\n",
      "[156]\ttrain-logloss:0.553589\teval-logloss:0.620787\n",
      "[157]\ttrain-logloss:0.553097\teval-logloss:0.620527\n",
      "[158]\ttrain-logloss:0.552543\teval-logloss:0.620349\n",
      "[159]\ttrain-logloss:0.551940\teval-logloss:0.620136\n",
      "[160]\ttrain-logloss:0.551400\teval-logloss:0.619982\n",
      "[161]\ttrain-logloss:0.550886\teval-logloss:0.619781\n",
      "[162]\ttrain-logloss:0.550404\teval-logloss:0.619697\n",
      "[163]\ttrain-logloss:0.549945\teval-logloss:0.619462\n",
      "[164]\ttrain-logloss:0.549320\teval-logloss:0.619164\n",
      "[165]\ttrain-logloss:0.548919\teval-logloss:0.618971\n",
      "[166]\ttrain-logloss:0.548340\teval-logloss:0.618811\n",
      "[167]\ttrain-logloss:0.547901\teval-logloss:0.618676\n",
      "[168]\ttrain-logloss:0.547306\teval-logloss:0.618498\n",
      "[169]\ttrain-logloss:0.546865\teval-logloss:0.618329\n",
      "[170]\ttrain-logloss:0.546290\teval-logloss:0.618072\n",
      "[171]\ttrain-logloss:0.545928\teval-logloss:0.617968\n",
      "[172]\ttrain-logloss:0.545416\teval-logloss:0.617806\n",
      "[173]\ttrain-logloss:0.544878\teval-logloss:0.617705\n",
      "[174]\ttrain-logloss:0.544443\teval-logloss:0.617537\n",
      "[175]\ttrain-logloss:0.543977\teval-logloss:0.617441\n",
      "[176]\ttrain-logloss:0.543552\teval-logloss:0.617335\n",
      "[177]\ttrain-logloss:0.543088\teval-logloss:0.617153\n",
      "[178]\ttrain-logloss:0.542612\teval-logloss:0.616983\n",
      "[179]\ttrain-logloss:0.542184\teval-logloss:0.616816\n",
      "[180]\ttrain-logloss:0.541732\teval-logloss:0.616757\n",
      "[181]\ttrain-logloss:0.541291\teval-logloss:0.616561\n",
      "[182]\ttrain-logloss:0.540875\teval-logloss:0.616440\n",
      "[183]\ttrain-logloss:0.540373\teval-logloss:0.616309\n",
      "[184]\ttrain-logloss:0.539851\teval-logloss:0.616111\n",
      "[185]\ttrain-logloss:0.539296\teval-logloss:0.615961\n",
      "[186]\ttrain-logloss:0.538926\teval-logloss:0.615904\n",
      "[187]\ttrain-logloss:0.538488\teval-logloss:0.615727\n",
      "[188]\ttrain-logloss:0.538056\teval-logloss:0.615640\n",
      "[189]\ttrain-logloss:0.537558\teval-logloss:0.615516\n",
      "[190]\ttrain-logloss:0.537016\teval-logloss:0.615342\n",
      "[191]\ttrain-logloss:0.536505\teval-logloss:0.615172\n",
      "[192]\ttrain-logloss:0.536091\teval-logloss:0.615035\n",
      "[193]\ttrain-logloss:0.535498\teval-logloss:0.614843\n",
      "[194]\ttrain-logloss:0.534948\teval-logloss:0.614635\n",
      "[195]\ttrain-logloss:0.534502\teval-logloss:0.614528\n",
      "[196]\ttrain-logloss:0.534084\teval-logloss:0.614449\n",
      "[197]\ttrain-logloss:0.533572\teval-logloss:0.614290\n",
      "[198]\ttrain-logloss:0.533246\teval-logloss:0.614187\n",
      "[199]\ttrain-logloss:0.532711\teval-logloss:0.614059\n",
      "[200]\ttrain-logloss:0.532310\teval-logloss:0.613989\n",
      "[201]\ttrain-logloss:0.531885\teval-logloss:0.613936\n",
      "[202]\ttrain-logloss:0.531416\teval-logloss:0.613815\n",
      "[203]\ttrain-logloss:0.531015\teval-logloss:0.613589\n",
      "[204]\ttrain-logloss:0.530474\teval-logloss:0.613459\n",
      "[205]\ttrain-logloss:0.530045\teval-logloss:0.613316\n",
      "[206]\ttrain-logloss:0.529657\teval-logloss:0.613305\n",
      "[207]\ttrain-logloss:0.529216\teval-logloss:0.613138\n",
      "[208]\ttrain-logloss:0.528695\teval-logloss:0.613031\n",
      "[209]\ttrain-logloss:0.528301\teval-logloss:0.612863\n",
      "[210]\ttrain-logloss:0.527833\teval-logloss:0.612723\n",
      "[211]\ttrain-logloss:0.527418\teval-logloss:0.612569\n",
      "[212]\ttrain-logloss:0.526985\teval-logloss:0.612401\n",
      "[213]\ttrain-logloss:0.526450\teval-logloss:0.612224\n",
      "[214]\ttrain-logloss:0.526049\teval-logloss:0.612180\n",
      "[215]\ttrain-logloss:0.525634\teval-logloss:0.612085\n",
      "[216]\ttrain-logloss:0.525264\teval-logloss:0.612008\n",
      "[217]\ttrain-logloss:0.524910\teval-logloss:0.611948\n",
      "[218]\ttrain-logloss:0.524493\teval-logloss:0.611804\n",
      "[219]\ttrain-logloss:0.524074\teval-logloss:0.611752\n",
      "[220]\ttrain-logloss:0.523703\teval-logloss:0.611666\n",
      "[221]\ttrain-logloss:0.523302\teval-logloss:0.611577\n",
      "[222]\ttrain-logloss:0.522952\teval-logloss:0.611456\n",
      "[223]\ttrain-logloss:0.522594\teval-logloss:0.611397\n",
      "[224]\ttrain-logloss:0.522225\teval-logloss:0.611386\n",
      "[225]\ttrain-logloss:0.521815\teval-logloss:0.611264\n",
      "[226]\ttrain-logloss:0.521407\teval-logloss:0.611145\n",
      "[227]\ttrain-logloss:0.521036\teval-logloss:0.611066\n",
      "[228]\ttrain-logloss:0.520630\teval-logloss:0.610929\n",
      "[229]\ttrain-logloss:0.520159\teval-logloss:0.610850\n",
      "[230]\ttrain-logloss:0.519787\teval-logloss:0.610778\n",
      "[231]\ttrain-logloss:0.519405\teval-logloss:0.610744\n",
      "[232]\ttrain-logloss:0.519023\teval-logloss:0.610538\n",
      "[233]\ttrain-logloss:0.518598\teval-logloss:0.610436\n",
      "[234]\ttrain-logloss:0.518267\teval-logloss:0.610322\n",
      "[235]\ttrain-logloss:0.517881\teval-logloss:0.610198\n",
      "[236]\ttrain-logloss:0.517495\teval-logloss:0.610186\n",
      "[237]\ttrain-logloss:0.517108\teval-logloss:0.610081\n",
      "[238]\ttrain-logloss:0.516779\teval-logloss:0.610028\n",
      "[239]\ttrain-logloss:0.516450\teval-logloss:0.609972\n",
      "[240]\ttrain-logloss:0.515937\teval-logloss:0.609818\n",
      "[241]\ttrain-logloss:0.515561\teval-logloss:0.609804\n",
      "[242]\ttrain-logloss:0.515013\teval-logloss:0.609626\n",
      "[243]\ttrain-logloss:0.514661\teval-logloss:0.609571\n",
      "[244]\ttrain-logloss:0.514318\teval-logloss:0.609494\n",
      "[245]\ttrain-logloss:0.513974\teval-logloss:0.609366\n",
      "[246]\ttrain-logloss:0.513654\teval-logloss:0.609291\n",
      "[247]\ttrain-logloss:0.513333\teval-logloss:0.609280\n",
      "[248]\ttrain-logloss:0.512863\teval-logloss:0.609201\n",
      "[249]\ttrain-logloss:0.512385\teval-logloss:0.609102\n",
      "[250]\ttrain-logloss:0.512053\teval-logloss:0.608939\n",
      "[251]\ttrain-logloss:0.511668\teval-logloss:0.608832\n",
      "[252]\ttrain-logloss:0.511340\teval-logloss:0.608728\n",
      "[253]\ttrain-logloss:0.510975\teval-logloss:0.608639\n",
      "[254]\ttrain-logloss:0.510579\teval-logloss:0.608534\n",
      "[255]\ttrain-logloss:0.510233\teval-logloss:0.608489\n",
      "[256]\ttrain-logloss:0.509832\teval-logloss:0.608393\n",
      "[257]\ttrain-logloss:0.509543\teval-logloss:0.608331\n",
      "[258]\ttrain-logloss:0.509153\teval-logloss:0.608194\n",
      "[259]\ttrain-logloss:0.508848\teval-logloss:0.608068\n",
      "[260]\ttrain-logloss:0.508426\teval-logloss:0.607962\n",
      "[261]\ttrain-logloss:0.508065\teval-logloss:0.607861\n",
      "[262]\ttrain-logloss:0.507583\teval-logloss:0.607736\n",
      "[263]\ttrain-logloss:0.507120\teval-logloss:0.607613\n",
      "[264]\ttrain-logloss:0.506680\teval-logloss:0.607497\n",
      "[265]\ttrain-logloss:0.506439\teval-logloss:0.607462\n",
      "[266]\ttrain-logloss:0.506116\teval-logloss:0.607339\n",
      "[267]\ttrain-logloss:0.505724\teval-logloss:0.607272\n",
      "[268]\ttrain-logloss:0.505270\teval-logloss:0.607159\n",
      "[269]\ttrain-logloss:0.504784\teval-logloss:0.607044\n",
      "[270]\ttrain-logloss:0.504426\teval-logloss:0.606988\n",
      "[271]\ttrain-logloss:0.504003\teval-logloss:0.606887\n",
      "[272]\ttrain-logloss:0.503720\teval-logloss:0.606883\n",
      "[273]\ttrain-logloss:0.503439\teval-logloss:0.606824\n",
      "[274]\ttrain-logloss:0.502952\teval-logloss:0.606648\n",
      "[275]\ttrain-logloss:0.502623\teval-logloss:0.606557\n",
      "[276]\ttrain-logloss:0.502321\teval-logloss:0.606504\n",
      "[277]\ttrain-logloss:0.502021\teval-logloss:0.606431\n",
      "[278]\ttrain-logloss:0.501681\teval-logloss:0.606365\n",
      "[279]\ttrain-logloss:0.501288\teval-logloss:0.606337\n",
      "[280]\ttrain-logloss:0.501018\teval-logloss:0.606326\n",
      "[281]\ttrain-logloss:0.500658\teval-logloss:0.606284\n",
      "[282]\ttrain-logloss:0.500409\teval-logloss:0.606189\n",
      "[283]\ttrain-logloss:0.500093\teval-logloss:0.606208\n",
      "[284]\ttrain-logloss:0.499832\teval-logloss:0.606194\n",
      "[285]\ttrain-logloss:0.499464\teval-logloss:0.606063\n",
      "[286]\ttrain-logloss:0.499168\teval-logloss:0.606013\n",
      "[287]\ttrain-logloss:0.498883\teval-logloss:0.605966\n",
      "[288]\ttrain-logloss:0.498514\teval-logloss:0.605896\n",
      "[289]\ttrain-logloss:0.498149\teval-logloss:0.605857\n",
      "[290]\ttrain-logloss:0.497914\teval-logloss:0.605880\n",
      "[291]\ttrain-logloss:0.497632\teval-logloss:0.605771\n",
      "[292]\ttrain-logloss:0.497219\teval-logloss:0.605616\n",
      "[293]\ttrain-logloss:0.496912\teval-logloss:0.605556\n",
      "[294]\ttrain-logloss:0.496448\teval-logloss:0.605435\n",
      "[295]\ttrain-logloss:0.495966\teval-logloss:0.605245\n",
      "[296]\ttrain-logloss:0.495695\teval-logloss:0.605223\n",
      "[297]\ttrain-logloss:0.495230\teval-logloss:0.605116\n",
      "[298]\ttrain-logloss:0.494806\teval-logloss:0.604984\n",
      "[299]\ttrain-logloss:0.494393\teval-logloss:0.604939\n",
      "[300]\ttrain-logloss:0.494101\teval-logloss:0.604920\n",
      "[301]\ttrain-logloss:0.493746\teval-logloss:0.604885\n",
      "[302]\ttrain-logloss:0.493388\teval-logloss:0.604824\n",
      "[303]\ttrain-logloss:0.493097\teval-logloss:0.604808\n",
      "[304]\ttrain-logloss:0.492853\teval-logloss:0.604759\n",
      "[305]\ttrain-logloss:0.492569\teval-logloss:0.604744\n",
      "[306]\ttrain-logloss:0.492233\teval-logloss:0.604691\n",
      "[307]\ttrain-logloss:0.491911\teval-logloss:0.604690\n",
      "[308]\ttrain-logloss:0.491474\teval-logloss:0.604531\n",
      "[309]\ttrain-logloss:0.491155\teval-logloss:0.604516\n",
      "[310]\ttrain-logloss:0.490906\teval-logloss:0.604458\n",
      "[311]\ttrain-logloss:0.490546\teval-logloss:0.604437\n",
      "[312]\ttrain-logloss:0.490112\teval-logloss:0.604335\n",
      "[313]\ttrain-logloss:0.489823\teval-logloss:0.604310\n",
      "[314]\ttrain-logloss:0.489582\teval-logloss:0.604277\n",
      "[315]\ttrain-logloss:0.489270\teval-logloss:0.604218\n",
      "[316]\ttrain-logloss:0.488993\teval-logloss:0.604207\n",
      "[317]\ttrain-logloss:0.488712\teval-logloss:0.604101\n",
      "[318]\ttrain-logloss:0.488403\teval-logloss:0.604063\n",
      "[319]\ttrain-logloss:0.488131\teval-logloss:0.604022\n",
      "[320]\ttrain-logloss:0.487888\teval-logloss:0.604015\n",
      "[321]\ttrain-logloss:0.487594\teval-logloss:0.603979\n",
      "[322]\ttrain-logloss:0.487340\teval-logloss:0.604004\n",
      "[323]\ttrain-logloss:0.487087\teval-logloss:0.603948\n",
      "[324]\ttrain-logloss:0.486735\teval-logloss:0.603903\n",
      "[325]\ttrain-logloss:0.486435\teval-logloss:0.603781\n",
      "[326]\ttrain-logloss:0.486071\teval-logloss:0.603742\n",
      "[327]\ttrain-logloss:0.485737\teval-logloss:0.603694\n",
      "[328]\ttrain-logloss:0.485405\teval-logloss:0.603714\n",
      "[329]\ttrain-logloss:0.485146\teval-logloss:0.603704\n",
      "[330]\ttrain-logloss:0.484737\teval-logloss:0.603677\n",
      "[331]\ttrain-logloss:0.484341\teval-logloss:0.603581\n",
      "[332]\ttrain-logloss:0.484006\teval-logloss:0.603523\n",
      "[333]\ttrain-logloss:0.483664\teval-logloss:0.603458\n",
      "[334]\ttrain-logloss:0.483399\teval-logloss:0.603468\n",
      "[335]\ttrain-logloss:0.483116\teval-logloss:0.603377\n",
      "[336]\ttrain-logloss:0.482819\teval-logloss:0.603348\n",
      "[337]\ttrain-logloss:0.482498\teval-logloss:0.603306\n",
      "[338]\ttrain-logloss:0.482250\teval-logloss:0.603290\n",
      "[339]\ttrain-logloss:0.481946\teval-logloss:0.603238\n",
      "[340]\ttrain-logloss:0.481645\teval-logloss:0.603250\n",
      "[341]\ttrain-logloss:0.481335\teval-logloss:0.603216\n",
      "[342]\ttrain-logloss:0.481001\teval-logloss:0.603214\n",
      "[343]\ttrain-logloss:0.480770\teval-logloss:0.603199\n",
      "[344]\ttrain-logloss:0.480446\teval-logloss:0.603104\n",
      "[345]\ttrain-logloss:0.480162\teval-logloss:0.603013\n",
      "[346]\ttrain-logloss:0.479873\teval-logloss:0.603004\n",
      "[347]\ttrain-logloss:0.479616\teval-logloss:0.602953\n",
      "[348]\ttrain-logloss:0.479352\teval-logloss:0.602908\n",
      "[349]\ttrain-logloss:0.478989\teval-logloss:0.602785\n",
      "[350]\ttrain-logloss:0.478715\teval-logloss:0.602721\n",
      "[351]\ttrain-logloss:0.478458\teval-logloss:0.602722\n",
      "[352]\ttrain-logloss:0.478184\teval-logloss:0.602693\n",
      "[353]\ttrain-logloss:0.477903\teval-logloss:0.602720\n",
      "[354]\ttrain-logloss:0.477647\teval-logloss:0.602730\n",
      "[355]\ttrain-logloss:0.477439\teval-logloss:0.602742\n",
      "[356]\ttrain-logloss:0.477153\teval-logloss:0.602693\n",
      "[357]\ttrain-logloss:0.476855\teval-logloss:0.602655\n",
      "[358]\ttrain-logloss:0.476530\teval-logloss:0.602585\n",
      "[359]\ttrain-logloss:0.476158\teval-logloss:0.602534\n",
      "[360]\ttrain-logloss:0.475804\teval-logloss:0.602548\n",
      "[361]\ttrain-logloss:0.475594\teval-logloss:0.602547\n",
      "[362]\ttrain-logloss:0.475318\teval-logloss:0.602501\n",
      "[363]\ttrain-logloss:0.475017\teval-logloss:0.602476\n",
      "[364]\ttrain-logloss:0.474780\teval-logloss:0.602411\n",
      "[365]\ttrain-logloss:0.474436\teval-logloss:0.602381\n",
      "[366]\ttrain-logloss:0.474232\teval-logloss:0.602359\n",
      "[367]\ttrain-logloss:0.474012\teval-logloss:0.602329\n",
      "[368]\ttrain-logloss:0.473772\teval-logloss:0.602260\n",
      "[369]\ttrain-logloss:0.473492\teval-logloss:0.602256\n",
      "[370]\ttrain-logloss:0.473217\teval-logloss:0.602239\n",
      "[371]\ttrain-logloss:0.472879\teval-logloss:0.602215\n",
      "[372]\ttrain-logloss:0.472630\teval-logloss:0.602172\n",
      "[373]\ttrain-logloss:0.472281\teval-logloss:0.602130\n",
      "[374]\ttrain-logloss:0.471921\teval-logloss:0.601973\n",
      "[375]\ttrain-logloss:0.471618\teval-logloss:0.601863\n",
      "[376]\ttrain-logloss:0.471362\teval-logloss:0.601869\n",
      "[377]\ttrain-logloss:0.471115\teval-logloss:0.601797\n",
      "[378]\ttrain-logloss:0.470822\teval-logloss:0.601820\n",
      "[379]\ttrain-logloss:0.470581\teval-logloss:0.601816\n",
      "[380]\ttrain-logloss:0.470297\teval-logloss:0.601816\n",
      "[381]\ttrain-logloss:0.470041\teval-logloss:0.601801\n",
      "[382]\ttrain-logloss:0.469816\teval-logloss:0.601857\n",
      "[383]\ttrain-logloss:0.469621\teval-logloss:0.601874\n",
      "[384]\ttrain-logloss:0.469358\teval-logloss:0.601856\n",
      "[385]\ttrain-logloss:0.469010\teval-logloss:0.601821\n",
      "[386]\ttrain-logloss:0.468682\teval-logloss:0.601822\n",
      "[387]\ttrain-logloss:0.468439\teval-logloss:0.601805\n",
      "[388]\ttrain-logloss:0.468215\teval-logloss:0.601792\n",
      "[389]\ttrain-logloss:0.467924\teval-logloss:0.601708\n",
      "[390]\ttrain-logloss:0.467600\teval-logloss:0.601745\n",
      "[391]\ttrain-logloss:0.467287\teval-logloss:0.601636\n",
      "[392]\ttrain-logloss:0.467055\teval-logloss:0.601561\n",
      "[393]\ttrain-logloss:0.466858\teval-logloss:0.601534\n",
      "[394]\ttrain-logloss:0.466548\teval-logloss:0.601459\n",
      "[395]\ttrain-logloss:0.466309\teval-logloss:0.601487\n",
      "[396]\ttrain-logloss:0.466091\teval-logloss:0.601476\n",
      "[397]\ttrain-logloss:0.465881\teval-logloss:0.601471\n",
      "[398]\ttrain-logloss:0.465677\teval-logloss:0.601512\n",
      "[399]\ttrain-logloss:0.465388\teval-logloss:0.601495\n",
      "[400]\ttrain-logloss:0.465163\teval-logloss:0.601490\n",
      "[401]\ttrain-logloss:0.464883\teval-logloss:0.601461\n",
      "[402]\ttrain-logloss:0.464691\teval-logloss:0.601460\n",
      "[403]\ttrain-logloss:0.464400\teval-logloss:0.601501\n",
      "[404]\ttrain-logloss:0.464126\teval-logloss:0.601459\n",
      "[405]\ttrain-logloss:0.463894\teval-logloss:0.601386\n",
      "[406]\ttrain-logloss:0.463661\teval-logloss:0.601339\n",
      "[407]\ttrain-logloss:0.463438\teval-logloss:0.601382\n",
      "[408]\ttrain-logloss:0.463181\teval-logloss:0.601384\n",
      "[409]\ttrain-logloss:0.462856\teval-logloss:0.601316\n",
      "[410]\ttrain-logloss:0.462596\teval-logloss:0.601299\n",
      "[411]\ttrain-logloss:0.462341\teval-logloss:0.601303\n",
      "[412]\ttrain-logloss:0.462054\teval-logloss:0.601310\n",
      "[413]\ttrain-logloss:0.461841\teval-logloss:0.601325\n",
      "[414]\ttrain-logloss:0.461652\teval-logloss:0.601313\n",
      "[415]\ttrain-logloss:0.461443\teval-logloss:0.601312\n",
      "[416]\ttrain-logloss:0.461215\teval-logloss:0.601318\n",
      "[417]\ttrain-logloss:0.460988\teval-logloss:0.601291\n",
      "[418]\ttrain-logloss:0.460806\teval-logloss:0.601312\n",
      "[419]\ttrain-logloss:0.460579\teval-logloss:0.601333\n",
      "[420]\ttrain-logloss:0.460350\teval-logloss:0.601325\n",
      "[421]\ttrain-logloss:0.460089\teval-logloss:0.601285\n",
      "[422]\ttrain-logloss:0.459914\teval-logloss:0.601276\n",
      "[423]\ttrain-logloss:0.459718\teval-logloss:0.601222\n",
      "[424]\ttrain-logloss:0.459360\teval-logloss:0.601159\n",
      "[425]\ttrain-logloss:0.459139\teval-logloss:0.601131\n",
      "[426]\ttrain-logloss:0.458705\teval-logloss:0.600988\n",
      "[427]\ttrain-logloss:0.458399\teval-logloss:0.600878\n",
      "[428]\ttrain-logloss:0.458112\teval-logloss:0.600833\n",
      "[429]\ttrain-logloss:0.457772\teval-logloss:0.600764\n",
      "[430]\ttrain-logloss:0.457479\teval-logloss:0.600779\n",
      "[431]\ttrain-logloss:0.457274\teval-logloss:0.600796\n",
      "[432]\ttrain-logloss:0.457033\teval-logloss:0.600753\n",
      "[433]\ttrain-logloss:0.456782\teval-logloss:0.600770\n",
      "[434]\ttrain-logloss:0.456588\teval-logloss:0.600818\n",
      "[435]\ttrain-logloss:0.456288\teval-logloss:0.600810\n",
      "[436]\ttrain-logloss:0.455979\teval-logloss:0.600779\n",
      "[437]\ttrain-logloss:0.455756\teval-logloss:0.600828\n",
      "[438]\ttrain-logloss:0.455523\teval-logloss:0.600842\n",
      "[439]\ttrain-logloss:0.455331\teval-logloss:0.600830\n",
      "[440]\ttrain-logloss:0.455117\teval-logloss:0.600797\n",
      "[441]\ttrain-logloss:0.454941\teval-logloss:0.600830\n",
      "[442]\ttrain-logloss:0.454649\teval-logloss:0.600770\n",
      "[443]\ttrain-logloss:0.454291\teval-logloss:0.600731\n",
      "[444]\ttrain-logloss:0.454117\teval-logloss:0.600680\n",
      "[445]\ttrain-logloss:0.453922\teval-logloss:0.600625\n",
      "[446]\ttrain-logloss:0.453704\teval-logloss:0.600641\n",
      "[447]\ttrain-logloss:0.453469\teval-logloss:0.600622\n",
      "[448]\ttrain-logloss:0.453232\teval-logloss:0.600605\n",
      "[449]\ttrain-logloss:0.453034\teval-logloss:0.600613\n",
      "[450]\ttrain-logloss:0.452850\teval-logloss:0.600596\n",
      "[451]\ttrain-logloss:0.452675\teval-logloss:0.600596\n",
      "[452]\ttrain-logloss:0.452401\teval-logloss:0.600644\n",
      "[453]\ttrain-logloss:0.452167\teval-logloss:0.600626\n",
      "[454]\ttrain-logloss:0.451964\teval-logloss:0.600614\n",
      "[455]\ttrain-logloss:0.451774\teval-logloss:0.600629\n",
      "[456]\ttrain-logloss:0.451606\teval-logloss:0.600655\n",
      "[457]\ttrain-logloss:0.451411\teval-logloss:0.600694\n",
      "[458]\ttrain-logloss:0.451198\teval-logloss:0.600733\n",
      "[459]\ttrain-logloss:0.450983\teval-logloss:0.600723\n",
      "[460]\ttrain-logloss:0.450777\teval-logloss:0.600759\n",
      "[461]\ttrain-logloss:0.450547\teval-logloss:0.600728\n",
      "[462]\ttrain-logloss:0.450404\teval-logloss:0.600774\n",
      "[463]\ttrain-logloss:0.450203\teval-logloss:0.600768\n",
      "[464]\ttrain-logloss:0.449913\teval-logloss:0.600649\n",
      "[465]\ttrain-logloss:0.449720\teval-logloss:0.600665\n",
      "[466]\ttrain-logloss:0.449438\teval-logloss:0.600604\n",
      "[467]\ttrain-logloss:0.449213\teval-logloss:0.600605\n",
      "[468]\ttrain-logloss:0.448958\teval-logloss:0.600654\n",
      "[469]\ttrain-logloss:0.448768\teval-logloss:0.600600\n",
      "[470]\ttrain-logloss:0.448453\teval-logloss:0.600555\n",
      "[471]\ttrain-logloss:0.448280\teval-logloss:0.600617\n",
      "[472]\ttrain-logloss:0.448089\teval-logloss:0.600672\n",
      "[473]\ttrain-logloss:0.447904\teval-logloss:0.600743\n",
      "[474]\ttrain-logloss:0.447650\teval-logloss:0.600747\n",
      "[475]\ttrain-logloss:0.447370\teval-logloss:0.600717\n",
      "[476]\ttrain-logloss:0.447186\teval-logloss:0.600723\n",
      "[477]\ttrain-logloss:0.446985\teval-logloss:0.600678\n",
      "[478]\ttrain-logloss:0.446709\teval-logloss:0.600647\n",
      "[479]\ttrain-logloss:0.446501\teval-logloss:0.600678\n",
      "[480]\ttrain-logloss:0.446350\teval-logloss:0.600747\n",
      "[481]\ttrain-logloss:0.446106\teval-logloss:0.600720\n",
      "[482]\ttrain-logloss:0.445955\teval-logloss:0.600757\n",
      "[483]\ttrain-logloss:0.445696\teval-logloss:0.600734\n",
      "[484]\ttrain-logloss:0.445443\teval-logloss:0.600790\n",
      "[485]\ttrain-logloss:0.445140\teval-logloss:0.600775\n",
      "[486]\ttrain-logloss:0.444985\teval-logloss:0.600791\n",
      "[487]\ttrain-logloss:0.444845\teval-logloss:0.600838\n",
      "[488]\ttrain-logloss:0.444610\teval-logloss:0.600870\n",
      "[489]\ttrain-logloss:0.444411\teval-logloss:0.600850\n",
      "[490]\ttrain-logloss:0.444194\teval-logloss:0.600857\n",
      "[491]\ttrain-logloss:0.444016\teval-logloss:0.600842\n",
      "[492]\ttrain-logloss:0.443817\teval-logloss:0.600852\n",
      "[493]\ttrain-logloss:0.443618\teval-logloss:0.600940\n",
      "[494]\ttrain-logloss:0.443448\teval-logloss:0.600930\n",
      "[495]\ttrain-logloss:0.443271\teval-logloss:0.600911\n",
      "[496]\ttrain-logloss:0.443108\teval-logloss:0.600918\n",
      "[497]\ttrain-logloss:0.442948\teval-logloss:0.601002\n",
      "[498]\ttrain-logloss:0.442776\teval-logloss:0.601064\n",
      "[499]\ttrain-logloss:0.442555\teval-logloss:0.601059\n",
      "[500]\ttrain-logloss:0.442392\teval-logloss:0.601103\n",
      "[501]\ttrain-logloss:0.442190\teval-logloss:0.601128\n",
      "[502]\ttrain-logloss:0.442015\teval-logloss:0.601134\n",
      "[503]\ttrain-logloss:0.441858\teval-logloss:0.601147\n",
      "[504]\ttrain-logloss:0.441622\teval-logloss:0.601124\n",
      "[505]\ttrain-logloss:0.441432\teval-logloss:0.601065\n",
      "[506]\ttrain-logloss:0.441239\teval-logloss:0.601031\n",
      "[507]\ttrain-logloss:0.441051\teval-logloss:0.601026\n",
      "[508]\ttrain-logloss:0.440900\teval-logloss:0.601024\n",
      "[509]\ttrain-logloss:0.440735\teval-logloss:0.601017\n",
      "[510]\ttrain-logloss:0.440547\teval-logloss:0.601071\n",
      "[511]\ttrain-logloss:0.440316\teval-logloss:0.601071\n",
      "[512]\ttrain-logloss:0.440142\teval-logloss:0.601052\n",
      "[513]\ttrain-logloss:0.439883\teval-logloss:0.601018\n",
      "[514]\ttrain-logloss:0.439598\teval-logloss:0.600930\n",
      "[515]\ttrain-logloss:0.439372\teval-logloss:0.600927\n",
      "[516]\ttrain-logloss:0.439101\teval-logloss:0.600878\n",
      "[517]\ttrain-logloss:0.438836\teval-logloss:0.600801\n",
      "[518]\ttrain-logloss:0.438568\teval-logloss:0.600815\n",
      "[519]\ttrain-logloss:0.438333\teval-logloss:0.600814\n",
      "[520]\ttrain-logloss:0.438120\teval-logloss:0.600799\n",
      "[521]\ttrain-logloss:0.437890\teval-logloss:0.600777\n",
      "[522]\ttrain-logloss:0.437732\teval-logloss:0.600806\n",
      "[523]\ttrain-logloss:0.437587\teval-logloss:0.600847\n",
      "[524]\ttrain-logloss:0.437454\teval-logloss:0.600820\n",
      "[525]\ttrain-logloss:0.437202\teval-logloss:0.600826\n",
      "[526]\ttrain-logloss:0.437025\teval-logloss:0.600867\n",
      "[527]\ttrain-logloss:0.436804\teval-logloss:0.600852\n",
      "[528]\ttrain-logloss:0.436561\teval-logloss:0.600887\n",
      "[529]\ttrain-logloss:0.436392\teval-logloss:0.600982\n",
      "[530]\ttrain-logloss:0.436200\teval-logloss:0.601050\n",
      "[531]\ttrain-logloss:0.436017\teval-logloss:0.601057\n",
      "[532]\ttrain-logloss:0.435843\teval-logloss:0.601125\n",
      "[533]\ttrain-logloss:0.435698\teval-logloss:0.601145\n",
      "[534]\ttrain-logloss:0.435566\teval-logloss:0.601200\n",
      "[535]\ttrain-logloss:0.435421\teval-logloss:0.601250\n",
      "[536]\ttrain-logloss:0.435272\teval-logloss:0.601274\n",
      "[537]\ttrain-logloss:0.435004\teval-logloss:0.601293\n",
      "[538]\ttrain-logloss:0.434859\teval-logloss:0.601307\n",
      "[539]\ttrain-logloss:0.434651\teval-logloss:0.601292\n",
      "[540]\ttrain-logloss:0.434475\teval-logloss:0.601339\n",
      "[541]\ttrain-logloss:0.434278\teval-logloss:0.601280\n",
      "[542]\ttrain-logloss:0.434146\teval-logloss:0.601278\n",
      "[543]\ttrain-logloss:0.434006\teval-logloss:0.601332\n",
      "[544]\ttrain-logloss:0.433839\teval-logloss:0.601353\n",
      "[545]\ttrain-logloss:0.433679\teval-logloss:0.601334\n",
      "[546]\ttrain-logloss:0.433528\teval-logloss:0.601366\n",
      "[547]\ttrain-logloss:0.433298\teval-logloss:0.601402\n",
      "[548]\ttrain-logloss:0.433081\teval-logloss:0.601335\n",
      "[549]\ttrain-logloss:0.432917\teval-logloss:0.601357\n",
      "[550]\ttrain-logloss:0.432723\teval-logloss:0.601365\n",
      "[551]\ttrain-logloss:0.432497\teval-logloss:0.601384\n",
      "[552]\ttrain-logloss:0.432380\teval-logloss:0.601442\n",
      "[553]\ttrain-logloss:0.432220\teval-logloss:0.601439\n",
      "[554]\ttrain-logloss:0.431983\teval-logloss:0.601465\n",
      "[555]\ttrain-logloss:0.431792\teval-logloss:0.601556\n",
      "[556]\ttrain-logloss:0.431647\teval-logloss:0.601554\n",
      "[557]\ttrain-logloss:0.431520\teval-logloss:0.601559\n",
      "[558]\ttrain-logloss:0.431071\teval-logloss:0.601347\n",
      "[559]\ttrain-logloss:0.430872\teval-logloss:0.601315\n",
      "[560]\ttrain-logloss:0.430610\teval-logloss:0.601301\n",
      "[561]\ttrain-logloss:0.430448\teval-logloss:0.601331\n",
      "[562]\ttrain-logloss:0.430284\teval-logloss:0.601310\n",
      "[563]\ttrain-logloss:0.430092\teval-logloss:0.601317\n",
      "[564]\ttrain-logloss:0.429881\teval-logloss:0.601278\n",
      "[565]\ttrain-logloss:0.429742\teval-logloss:0.601356\n",
      "[566]\ttrain-logloss:0.429600\teval-logloss:0.601362\n",
      "[567]\ttrain-logloss:0.429426\teval-logloss:0.601365\n",
      "[568]\ttrain-logloss:0.429225\teval-logloss:0.601360\n",
      "[569]\ttrain-logloss:0.429040\teval-logloss:0.601387\n",
      "[570]\ttrain-logloss:0.428859\teval-logloss:0.601384\n",
      "[571]\ttrain-logloss:0.428597\teval-logloss:0.601332\n",
      "[572]\ttrain-logloss:0.428417\teval-logloss:0.601353\n",
      "[573]\ttrain-logloss:0.428231\teval-logloss:0.601319\n",
      "[574]\ttrain-logloss:0.428067\teval-logloss:0.601331\n",
      "[575]\ttrain-logloss:0.427781\teval-logloss:0.601336\n",
      "[576]\ttrain-logloss:0.427605\teval-logloss:0.601379\n",
      "[577]\ttrain-logloss:0.427343\teval-logloss:0.601404\n",
      "[578]\ttrain-logloss:0.427182\teval-logloss:0.601394\n",
      "[579]\ttrain-logloss:0.427028\teval-logloss:0.601420\n",
      "[580]\ttrain-logloss:0.426912\teval-logloss:0.601398\n",
      "[581]\ttrain-logloss:0.426763\teval-logloss:0.601412\n",
      "[582]\ttrain-logloss:0.426637\teval-logloss:0.601451\n",
      "[583]\ttrain-logloss:0.426507\teval-logloss:0.601525\n",
      "[584]\ttrain-logloss:0.426289\teval-logloss:0.601506\n",
      "[585]\ttrain-logloss:0.426095\teval-logloss:0.601533\n",
      "[586]\ttrain-logloss:0.425954\teval-logloss:0.601608\n",
      "[587]\ttrain-logloss:0.425822\teval-logloss:0.601602\n",
      "[588]\ttrain-logloss:0.425567\teval-logloss:0.601572\n",
      "[589]\ttrain-logloss:0.425440\teval-logloss:0.601592\n",
      "[590]\ttrain-logloss:0.425281\teval-logloss:0.601641\n",
      "[591]\ttrain-logloss:0.425138\teval-logloss:0.601667\n",
      "[592]\ttrain-logloss:0.425027\teval-logloss:0.601681\n",
      "[593]\ttrain-logloss:0.424896\teval-logloss:0.601760\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = train_data, label = train_labels)\n",
    "Xdatatest = xgboost.DMatrix(data = test_data, label = test_labels)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.692112\teval-logloss:0.692331\n",
      "[1]\ttrain-logloss:0.690966\teval-logloss:0.691626\n",
      "[2]\ttrain-logloss:0.690063\teval-logloss:0.691127\n",
      "[3]\ttrain-logloss:0.689281\teval-logloss:0.690595\n",
      "[4]\ttrain-logloss:0.688442\teval-logloss:0.690320\n",
      "[5]\ttrain-logloss:0.687842\teval-logloss:0.690062\n",
      "[6]\ttrain-logloss:0.687131\teval-logloss:0.689804\n",
      "[7]\ttrain-logloss:0.686442\teval-logloss:0.689340\n",
      "[8]\ttrain-logloss:0.685796\teval-logloss:0.689001\n",
      "[9]\ttrain-logloss:0.685025\teval-logloss:0.688842\n",
      "[10]\ttrain-logloss:0.684591\teval-logloss:0.688549\n",
      "[11]\ttrain-logloss:0.683832\teval-logloss:0.688139\n",
      "[12]\ttrain-logloss:0.683208\teval-logloss:0.687889\n",
      "[13]\ttrain-logloss:0.682690\teval-logloss:0.687725\n",
      "[14]\ttrain-logloss:0.682203\teval-logloss:0.687506\n",
      "[15]\ttrain-logloss:0.681642\teval-logloss:0.687321\n",
      "[16]\ttrain-logloss:0.680971\teval-logloss:0.686889\n",
      "[17]\ttrain-logloss:0.680593\teval-logloss:0.686738\n",
      "[18]\ttrain-logloss:0.679950\teval-logloss:0.686580\n",
      "[19]\ttrain-logloss:0.679447\teval-logloss:0.686357\n",
      "[20]\ttrain-logloss:0.678993\teval-logloss:0.686151\n",
      "[21]\ttrain-logloss:0.678353\teval-logloss:0.685999\n",
      "[22]\ttrain-logloss:0.677883\teval-logloss:0.685642\n",
      "[23]\ttrain-logloss:0.677332\teval-logloss:0.685410\n",
      "[24]\ttrain-logloss:0.676863\teval-logloss:0.685150\n",
      "[25]\ttrain-logloss:0.676234\teval-logloss:0.684802\n",
      "[26]\ttrain-logloss:0.675761\teval-logloss:0.684461\n",
      "[27]\ttrain-logloss:0.675314\teval-logloss:0.684422\n",
      "[28]\ttrain-logloss:0.674844\teval-logloss:0.684227\n",
      "[29]\ttrain-logloss:0.674487\teval-logloss:0.683993\n",
      "[30]\ttrain-logloss:0.674041\teval-logloss:0.683748\n",
      "[31]\ttrain-logloss:0.673477\teval-logloss:0.683561\n",
      "[32]\ttrain-logloss:0.673063\teval-logloss:0.683557\n",
      "[33]\ttrain-logloss:0.672600\teval-logloss:0.683344\n",
      "[34]\ttrain-logloss:0.672193\teval-logloss:0.683141\n",
      "[35]\ttrain-logloss:0.671793\teval-logloss:0.683090\n",
      "[36]\ttrain-logloss:0.671500\teval-logloss:0.682910\n",
      "[37]\ttrain-logloss:0.671016\teval-logloss:0.682664\n",
      "[38]\ttrain-logloss:0.670509\teval-logloss:0.682513\n",
      "[39]\ttrain-logloss:0.670202\teval-logloss:0.682302\n",
      "[40]\ttrain-logloss:0.669847\teval-logloss:0.682047\n",
      "[41]\ttrain-logloss:0.669432\teval-logloss:0.681984\n",
      "[42]\ttrain-logloss:0.668926\teval-logloss:0.681796\n",
      "[43]\ttrain-logloss:0.668592\teval-logloss:0.681691\n",
      "[44]\ttrain-logloss:0.668165\teval-logloss:0.681510\n",
      "[45]\ttrain-logloss:0.667693\teval-logloss:0.681400\n",
      "[46]\ttrain-logloss:0.667286\teval-logloss:0.681159\n",
      "[47]\ttrain-logloss:0.666920\teval-logloss:0.681049\n",
      "[48]\ttrain-logloss:0.666482\teval-logloss:0.680851\n",
      "[49]\ttrain-logloss:0.666250\teval-logloss:0.680634\n",
      "[50]\ttrain-logloss:0.665874\teval-logloss:0.680352\n",
      "[51]\ttrain-logloss:0.665457\teval-logloss:0.680210\n",
      "[52]\ttrain-logloss:0.665042\teval-logloss:0.680060\n",
      "[53]\ttrain-logloss:0.664666\teval-logloss:0.679954\n",
      "[54]\ttrain-logloss:0.664306\teval-logloss:0.679800\n",
      "[55]\ttrain-logloss:0.663945\teval-logloss:0.679576\n",
      "[56]\ttrain-logloss:0.663589\teval-logloss:0.679582\n",
      "[57]\ttrain-logloss:0.663215\teval-logloss:0.679438\n",
      "[58]\ttrain-logloss:0.662907\teval-logloss:0.679308\n",
      "[59]\ttrain-logloss:0.662541\teval-logloss:0.679311\n",
      "[60]\ttrain-logloss:0.662128\teval-logloss:0.679374\n",
      "[61]\ttrain-logloss:0.661680\teval-logloss:0.679191\n",
      "[62]\ttrain-logloss:0.661311\teval-logloss:0.679098\n",
      "[63]\ttrain-logloss:0.660960\teval-logloss:0.679050\n",
      "[64]\ttrain-logloss:0.660724\teval-logloss:0.678968\n",
      "[65]\ttrain-logloss:0.660354\teval-logloss:0.678640\n",
      "[66]\ttrain-logloss:0.659856\teval-logloss:0.678363\n",
      "[67]\ttrain-logloss:0.659611\teval-logloss:0.678280\n",
      "[68]\ttrain-logloss:0.659330\teval-logloss:0.678058\n",
      "[69]\ttrain-logloss:0.659050\teval-logloss:0.678022\n",
      "[70]\ttrain-logloss:0.658605\teval-logloss:0.677872\n",
      "[71]\ttrain-logloss:0.658225\teval-logloss:0.677652\n",
      "[72]\ttrain-logloss:0.658012\teval-logloss:0.677519\n",
      "[73]\ttrain-logloss:0.657664\teval-logloss:0.677549\n",
      "[74]\ttrain-logloss:0.657279\teval-logloss:0.677464\n",
      "[75]\ttrain-logloss:0.656893\teval-logloss:0.677316\n",
      "[76]\ttrain-logloss:0.656557\teval-logloss:0.677100\n",
      "[77]\ttrain-logloss:0.656278\teval-logloss:0.676970\n",
      "[78]\ttrain-logloss:0.655924\teval-logloss:0.676944\n",
      "[79]\ttrain-logloss:0.655547\teval-logloss:0.676922\n",
      "[80]\ttrain-logloss:0.655209\teval-logloss:0.676656\n",
      "[81]\ttrain-logloss:0.654993\teval-logloss:0.676580\n",
      "[82]\ttrain-logloss:0.654571\teval-logloss:0.676558\n",
      "[83]\ttrain-logloss:0.654323\teval-logloss:0.676466\n",
      "[84]\ttrain-logloss:0.653900\teval-logloss:0.676136\n",
      "[85]\ttrain-logloss:0.653599\teval-logloss:0.675918\n",
      "[86]\ttrain-logloss:0.653267\teval-logloss:0.675829\n",
      "[87]\ttrain-logloss:0.652973\teval-logloss:0.675733\n",
      "[88]\ttrain-logloss:0.652677\teval-logloss:0.675609\n",
      "[89]\ttrain-logloss:0.652466\teval-logloss:0.675506\n",
      "[90]\ttrain-logloss:0.652191\teval-logloss:0.675455\n",
      "[91]\ttrain-logloss:0.651860\teval-logloss:0.675391\n",
      "[92]\ttrain-logloss:0.651558\teval-logloss:0.675309\n",
      "[93]\ttrain-logloss:0.651318\teval-logloss:0.675133\n",
      "[94]\ttrain-logloss:0.650952\teval-logloss:0.675100\n",
      "[95]\ttrain-logloss:0.650704\teval-logloss:0.675060\n",
      "[96]\ttrain-logloss:0.650299\teval-logloss:0.674868\n",
      "[97]\ttrain-logloss:0.650008\teval-logloss:0.674619\n",
      "[98]\ttrain-logloss:0.649709\teval-logloss:0.674444\n",
      "[99]\ttrain-logloss:0.649503\teval-logloss:0.674331\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = X_train, label = y_train)\n",
    "Xdatatest = xgboost.DMatrix(data = X_test, label = y_test)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss alg =  0.637214501074\n",
      "Log_loss bst =  0.674337547331\n"
     ]
    }
   ],
   "source": [
    "alg.fit(X_train, y_train)\n",
    "y_pred_alg = alg.predict_proba(X_test)[:, 1]\n",
    "print \"Log_loss alg = \", log_loss(y_test, y_pred_alg)\n",
    "y_pred_bst = bst.predict(xgboost.DMatrix(X_test))\n",
    "print \"Log_loss bst = \", log_loss(y_test, y_pred_bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss alg =  0.603468642561\n",
      "Log_loss bst =  0.601759704424\n"
     ]
    }
   ],
   "source": [
    "alg.fit(train_data, train_labels)\n",
    "y_pred_alg = alg.predict_proba(test_data)[:, 1]\n",
    "print \"Log_loss alg = \", log_loss(test_labels, y_pred_alg)\n",
    "y_pred_bst = bst.predict(xgboost.DMatrix(test_data))\n",
    "print \"Log_loss bst = \", log_loss(test_labels, y_pred_bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def losses_func(w):\n",
    "    return log_loss(test_labels, (y_pred_alg*w[0] + y_pred_bst*w[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = opt.minimize(losses_func, method='Nelder-Mead', x0=[-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582819318456\n"
     ]
    }
   ],
   "source": [
    "print x.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_alg_submission = alg.predict_proba(X_test_submission)[:,1]\n",
    "y_test_bst_submission = bst.predict(xgboost.DMatrix(X_test_submission))\n",
    "y_test_submission = y_test_alg_submission*x.x[0] + y_test_bst_submission*x.x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = sample_submission.copy()\n",
    "\n",
    "for i in range(len(y_test_submission)):\n",
    "    c = y_test_submission[i]\n",
    "    if(c <= 0.02):\n",
    "        y_test_submission[i] = 0.0\n",
    "    if(c >= 0.98):\n",
    "        y_test_submission[i] = 1.0\n",
    "        \n",
    "for c in y_test_submission:\n",
    "    if(c < 0 or c>1):\n",
    "        print c\n",
    "        \n",
    "ss.target = y_test_submission\n",
    "ss.to_csv('Double-alg-xgboost-lin_part1', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
