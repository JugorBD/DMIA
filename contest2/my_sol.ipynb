{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "from sklearn import manifold, decomposition, linear_model, ensemble, neighbors, cross_validation\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost\n",
    "import re\n",
    "\n",
    "from heamy.dataset import Dataset\n",
    "from heamy.estimator import Regressor, Classifier\n",
    "from heamy.pipeline import ModelsPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### будем использовать в качестве метрики RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(x,y):\n",
    "    return np.mean((x - y) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### загрузка данных url_domain_train. Пока работаем только с ними"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_train_df = pd.read_csv('data/url_domain_train.csv', header=None, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_train_df.columns = ['id', 'url', 'count']\n",
    "urls_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### нужно учесть count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### попробуем разбивать url'ы на части: login.rutracker.org $\\to$ 'login rutracker org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_tmp = urls_train_df\n",
    "sep_tmp['url'] = sep_tmp['url'].astype('str')\n",
    "sep_tmp['space'] = ' '\n",
    "sep_tmp['array_of_url'] = (sep_tmp['url'] + sep_tmp['space']).apply(lambda x: re.findall(r\"[\\w']+\",x)) * sep_tmp['count']\n",
    "sep_tmp.drop(['space'], axis = 1, inplace=True)\n",
    "sep_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_URLS = pd.DataFrame(sep_tmp.groupby('id').array_of_url.apply(lambda x: x.tolist()))\n",
    "sep_URLS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### без разбиения самих url'ов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = urls_train_df\n",
    "tmp['url'] = tmp['url'].astype('str')\n",
    "tmp['space'] = ' '\n",
    "tmp['array_of_url'] = (tmp['url'] + tmp['space']).apply(lambda x: x.split(' ')[:-1]) * tmp['count']\n",
    "tmp.drop(['space'], axis = 1, inplace=True)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URLS = pd.DataFrame(tmp.groupby('id').array_of_url.apply(lambda x: x.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_URLS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URLS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sep_f(x):\n",
    "    a = []\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            a.append(x[i][j])\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    a = []\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            a.append(x[i][j])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URLS['list'] = URLS.array_of_url.apply(f)\n",
    "URLS.drop(['array_of_url'], axis = 1, inplace=True)\n",
    "\n",
    "sep_URLS['list'] = sep_URLS.array_of_url.apply(sep_f)\n",
    "sep_URLS.drop(['array_of_url'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "URLS['id'] = URLS.index\n",
    "URLS.index = range(len(URLS))\n",
    "URLS.columns = ['urls', 'id']\n",
    "\n",
    "sep_URLS['id'] = sep_URLS.index\n",
    "sep_URLS.index = range(len(sep_URLS))\n",
    "sep_URLS.columns = ['urls', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_train_df = pd.read_csv('data/age_profile_train.csv', header=None, delimiter='\\t')\n",
    "age_train_df.columns = ['id', 'age']\n",
    "age_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = URLS.merge(age_train_df, on='id', how='left')\n",
    "sep_train_df = sep_URLS.merge(age_train_df, on = 'id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### начнём делать кросс-валидацию и обработку признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df.age.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.urls = train_df.urls.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.urls[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_train_df.urls[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "X = tfidf.fit_transform(train_df.urls.values)\n",
    "\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "sep_X = tfidf.fit_transform(sep_train_df.urls.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sep_X.shape\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "sep_score = []\n",
    "for k in range(5):\n",
    "    mean = []\n",
    "    sep_mean = []\n",
    "    for i in range(5):\n",
    "\n",
    "    \n",
    "        #train_data, test_data, y_train, y_test = cross_validation.train_test_split(X_nmf, y, \\\n",
    "        #                                                             test_size = 0.3)\n",
    "    \n",
    "        #xgb_rg = xgboost.XGBRegressor(n_estimators=n, learning_rate=0.03)\n",
    "        #xgb_rg.fit(train_data, y_train)\n",
    "        #print 'xgboost_rmse = ', rmse(xgb_rg.predict(test_data), y_test)\n",
    "        #mean.append(rmse(xgb_rg.predict(test_data), y_test))\n",
    "        \n",
    "        train_data, test_data, y_train, y_test = cross_validation.train_test_split(X, y,\\\n",
    "                                                                                  test_size = 0.3)\n",
    "        lin_reg = linear_model.SGDRegressor(n_iter=650, alpha=0.000008)\n",
    "        lin_reg.fit(train_data, y_train)\n",
    "        print rmse(lin_reg.predict(test_data), y_test)\n",
    "        mean.append(rmse(lin_reg.predict(test_data), y_test))\n",
    "        \n",
    "        train_data, test_data, y_train, y_test = cross_validation.train_test_split(sep_X, y,\\\n",
    "                                                                                  test_size = 0.3)\n",
    "        lin_reg = linear_model.SGDRegressor(n_iter=650, alpha=0.000008)\n",
    "        lin_reg.fit(train_data, y_train)\n",
    "        print 'with sep urls ',rmse(lin_reg.predict(test_data), y_test)\n",
    "        sep_mean.append(rmse(lin_reg.predict(test_data), y_test))\n",
    "        \n",
    "    score.append(np.mean(mean))\n",
    "    sep_score.append(np.mean(sep_mean))\n",
    "print np.mean(score)\n",
    "print 'in general with sep =', np.mean(sep_score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### с раздельными url'ами лучше!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = decomposition.NMF(n_components=200)\n",
    "model.fit(sep_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_nmf[itrain, :], y[itrain])\n",
    "\n",
    "pred_X_nmf = reg.predict(X_nmf[itest, :])\n",
    "print rmse(y[itest], pred_X_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = []\n",
    "for w in np.linspace(0, 1, 100):\n",
    "     error += [rmse(y[itest], pred_X * w + (1-w) * pred_X_nmf)]\n",
    "\n",
    "pd.Series(error, index=np.linspace(0, 1, 100)).plot(figsize=(6,3))\n",
    "print min(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import pipeline, preprocessing, feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# обычный датасет\n",
    "dataset1 = Dataset(X[itrain, :], y[itrain], X[itest, :])\n",
    "# NMF\n",
    "dataset2 = Dataset(X_nmf[itrain, :], y[itrain], X_nmf[itest, :])\n",
    "\n",
    "# линейная модель на обычных данных\n",
    "lr = Regressor(dataset=dataset1, \n",
    "                     estimator=linear_model.LinearRegression,\n",
    "                     parameters={'normalize': True},\n",
    "                     name='lr')\n",
    "\n",
    "# линейная модель на TFIDF от обычных данных\n",
    "def tfidf_lr_(X_train, y_train, X_test, y_test=None, random_state=8888):\n",
    "    model = pipeline.Pipeline([('tfidf', feature_extraction.text.TfidfTransformer()), \n",
    "                                ('linear_model', linear_model.LinearRegression())])\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "tfidf_lr = Regressor(dataset=dataset1,\n",
    "                     estimator=tfidf_lr_,\n",
    "                     name='tfidf_lr')\n",
    "\n",
    "# ExtraTrees на NMF\n",
    "rf = Regressor(dataset=dataset2, \n",
    "                     estimator=ensemble.ExtraTreesRegressor,\n",
    "                     parameters={'n_estimators': 100, 'n_jobs': -1},\n",
    "                     name='rf')\n",
    "\n",
    "# Stack two models\n",
    "# Returns new dataset with out-of-fold predictions\n",
    "meta_pipeline = ModelsPipeline(lr, tfidf_lr, rf)\n",
    "stack_ds = meta_pipeline.blend(proportion=0.2,seed=111)\n",
    "\n",
    "# Train LinearRegression on stacked data (second stage)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression)\n",
    "results = stacker.predict()\n",
    "\n",
    "print rmse(y[itest], results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь загрузим title_unify_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_train = pd.read_csv('data/title_unify_train.csv', header=None, sep='\\t')\n",
    "title_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_train.columns = ['id', 'unify', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = title_train\n",
    "tmp['unify'] = tmp['unify'].astype('str')\n",
    "tmp['space'] = ' '\n",
    "tmp['array_of_unify'] = (tmp['unify'] + tmp['space']).apply(lambda x: x.split(' ')[:-1]) * tmp['count']\n",
    "tmp.drop(['space'], axis = 1, inplace=True)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UNIFY = pd.DataFrame(tmp.groupby('id').array_of_unify.apply(lambda x: x.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UNIFY['list'] = UNIFY.array_of_unify.apply(f)\n",
    "UNIFY.drop(['array_of_unify'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UNIFY['id'] = UNIFY.index\n",
    "UNIFY.index = range(len(UNIFY))\n",
    "UNIFY.columns = ['unify', 'id']\n",
    "UNIFY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_un = UNIFY.merge(age_train_df, on='id', how='left')\n",
    "train_un.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = train_un.unify.values, train_un.age.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = map(lambda x: ' '.join(x), X)\n",
    "hw = HashingVectorizer(n_features=1500, non_negative=True).fit(X)\n",
    "X_to_den = hw.transform(X).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transformer = sklearn.decomposition.NMF(n_components=100)\n",
    "X_nmf = transformer.fit_transform(X_to_den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itrain, itest = cross_validation.train_test_split(range(len(X)), test_size=1./3, random_state=0)\n",
    "len(itrain), len(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse(y[itest], np.mean(y[itrain]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X[itrain, :], y[itrain])\n",
    "\n",
    "pred_X = reg.predict(X[itest, :])\n",
    "print rmse(y[itest], pred_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_nmf[itrain, :], y[itrain])\n",
    "\n",
    "pred_X_nmf = reg.predict(X_nmf[itest, :])\n",
    "print rmse(y[itest], pred_X_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = []\n",
    "for w in np.linspace(0, 1, 100):\n",
    "     error += [rmse(y[itest], pred_X * w + (1-w) * pred_X_nmf)]\n",
    "\n",
    "pd.Series(error, index=np.linspace(0, 1, 100)).plot(figsize=(6,3))\n",
    "print min(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# обычный датасет\n",
    "dataset1 = Dataset(X[itrain, :], y[itrain], X[itest, :])\n",
    "# NMF\n",
    "dataset2 = Dataset(X_nmf[itrain, :], y[itrain], X_nmf[itest, :])\n",
    "\n",
    "# линейная модель на обычных данных\n",
    "lr = Regressor(dataset=dataset1, \n",
    "                     estimator=linear_model.LinearRegression,\n",
    "                     parameters={'normalize': True},\n",
    "                     name='lr')\n",
    "\n",
    "# линейная модель на TFIDF от обычных данных\n",
    "def tfidf_lr_(X_train, y_train, X_test, y_test=None, random_state=8888):\n",
    "    model = pipeline.Pipeline([('tfidf', feature_extraction.text.TfidfTransformer()), \n",
    "                                ('linear_model', linear_model.LinearRegression())])\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "tfidf_lr = Regressor(dataset=dataset1,\n",
    "                     estimator=tfidf_lr_,\n",
    "                     name='tfidf_lr')\n",
    "\n",
    "# ExtraTrees на NMF\n",
    "rf = Regressor(dataset=dataset2, \n",
    "                     estimator=ensemble.ExtraTreesRegressor,\n",
    "                     parameters={'n_estimators': 100, 'n_jobs': -1},\n",
    "                     name='rf')\n",
    "\n",
    "# Stack two models\n",
    "# Returns new dataset with out-of-fold predictions\n",
    "meta_pipeline = ModelsPipeline(lr, tfidf_lr, rf)\n",
    "stack_ds = meta_pipeline.blend(proportion=0.2,seed=111)\n",
    "\n",
    "# Train LinearRegression on stacked data (second stage)\n",
    "stacker = Regressor(dataset=stack_ds, estimator=LinearRegression)\n",
    "results = stacker.predict()\n",
    "\n",
    "print rmse(y[itest], results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### данные для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_test_df = pd.read_csv('data/url_domain_test.csv', header=None, delimiter='\\t')\n",
    "urls_test_df.columns = ['id', 'url', 'count']\n",
    "urls_test_df.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sep_tmp = urls_test_df\n",
    "sep_tmp['url'] = sep_tmp['url'].astype('str')\n",
    "sep_tmp['space'] = ' '\n",
    "sep_tmp['array_of_url'] = (sep_tmp['url'] + sep_tmp['space']).apply(lambda x: re.findall(r\"[\\w']+\",x)) * sep_tmp['count']\n",
    "sep_tmp.drop(['space'], axis = 1, inplace=True)\n",
    "sep_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_URLS = pd.DataFrame(sep_tmp.groupby('id').array_of_url.apply(lambda x: x.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_URLS['list'] = TEST_URLS.array_of_url.apply(sep_f)\n",
    "TEST_URLS.drop(['array_of_url'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_URLS['id'] = TEST_URLS.index\n",
    "TEST_URLS.index = range(len(TEST_URLS))\n",
    "TEST_URLS.columns = ['urls', 'id']\n",
    "TEST_URLS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test= tfidf.transform(TEST_URLS.urls.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lin_reg = linear_model.SGDRegressor(n_iter=750, alpha=0.000008)\n",
    "lin_reg.fit(sep_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_URLS['age'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_URLS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_URLS = TEST_URLS[['id', 'age']]\n",
    "TEST_URLS.columns = ['Id', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_array = TEST_URLS.age.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_array*np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_sol = pd.read_csv('data/sample_submission.csv')\n",
    "random_sol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "miss_idx = set(random_sol.Id.values) - set(TEST_URLS.Id.values)\n",
    "miss_df = pd.DataFrame(zip(list(miss_idx), mean_array*np.ones(len(miss_idx))))\n",
    "miss_df.columns = ['Id', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_URLS = TEST_URLS.append(miss_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_URLS.to_csv('my_solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_URLS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print urls_test_df.shape\n",
    "print TEST_URLS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print urls_test_df.id.nunique()\n",
    "print TEST_URLS.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
