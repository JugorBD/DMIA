{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Roman/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/Roman/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # calculations with arrays\n",
    "import pandas as pd # user-friendly DataFrames for data representation\n",
    "import sklearn # machine learning algorithms\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "import xgboost as xgboost\n",
    "import matplotlib.pyplot as plt # import plot functions\n",
    "# necessary to plot in jupyter notebook:\n",
    "%matplotlib inline\n",
    "import seaborn as sns # make plots beautiful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Classification and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2998</td>\n",
       "      <td>19</td>\n",
       "      <td>317</td>\n",
       "      <td>131</td>\n",
       "      <td>336</td>\n",
       "      <td>278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2998</td>\n",
       "      <td>28</td>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>301</td>\n",
       "      <td>259</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  day  team1  team2  score1  score2 target\n",
       "0  2998   19    317    131     336     278   True\n",
       "1  2998   28     61     29     301     259   True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3021</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2\n",
       "0   0  3021    363    161\n",
       "1   1  3021    286      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "train_team1 = pd.DataFrame(enc.fit_transform(train[['team1']]))\n",
    "train_team2 = pd.DataFrame(enc.transform(train[['team2']]))\n",
    "train_teams = pd.concat([train_team1, train_team2], axis=1)\n",
    "\n",
    "test_team1 = pd.DataFrame(enc.transform(test[['team1']]))\n",
    "test_team2 = pd.DataFrame(enc.transform(test[['team2']]))\n",
    "test_teams = pd.concat([test_team1, test_team2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125207, 706)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_teams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([train[['year']], train_teams], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_submission = pd.concat([test[['year']], test_teams], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125207, 707)\n",
      "162\n",
      "1\n",
      "113\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "print X_test_submission.shape\n",
    "for c in test.team2.unique():\n",
    "    if(c not in train.team1.unique()):\n",
    "        print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X[X['year'] <= 3014]\n",
    "y_train = train[train['year'] <= 3014].target\n",
    "X_test = X[X['year'] > 3014]\n",
    "y_test = train[train['year'] > 3014].target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
       "        tol=0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = alg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.193379599483086"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00099407, -0.05548319, -0.06027442])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.coef_[0, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент при years мал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Взвешенная сумма алгоритмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = linear_model.LogisticRegression(C = 0.8)\n",
    "\n",
    "param = {}\n",
    "param['max_depth'] = 20\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.1\n",
    "\n",
    "numround = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = sklearn.cross_validation.train_test_split(X, train.target,  \n",
    "                                                                                     test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.690554\teval-logloss:0.690979\n",
      "[1]\ttrain-logloss:0.688521\teval-logloss:0.689344\n",
      "[2]\ttrain-logloss:0.686899\teval-logloss:0.687863\n",
      "[3]\ttrain-logloss:0.684698\teval-logloss:0.686700\n",
      "[4]\ttrain-logloss:0.683595\teval-logloss:0.685478\n",
      "[5]\ttrain-logloss:0.682041\teval-logloss:0.684371\n",
      "[6]\ttrain-logloss:0.680610\teval-logloss:0.683469\n",
      "[7]\ttrain-logloss:0.678727\teval-logloss:0.682620\n",
      "[8]\ttrain-logloss:0.677857\teval-logloss:0.681584\n",
      "[9]\ttrain-logloss:0.676553\teval-logloss:0.680669\n",
      "[10]\ttrain-logloss:0.675287\teval-logloss:0.679989\n",
      "[11]\ttrain-logloss:0.673759\teval-logloss:0.679043\n",
      "[12]\ttrain-logloss:0.672706\teval-logloss:0.678417\n",
      "[13]\ttrain-logloss:0.671291\teval-logloss:0.677512\n",
      "[14]\ttrain-logloss:0.670350\teval-logloss:0.676726\n",
      "[15]\ttrain-logloss:0.669061\teval-logloss:0.675829\n",
      "[16]\ttrain-logloss:0.667831\teval-logloss:0.675146\n",
      "[17]\ttrain-logloss:0.666838\teval-logloss:0.674399\n",
      "[18]\ttrain-logloss:0.665771\teval-logloss:0.673774\n",
      "[19]\ttrain-logloss:0.664729\teval-logloss:0.673393\n",
      "[20]\ttrain-logloss:0.663421\teval-logloss:0.672595\n",
      "[21]\ttrain-logloss:0.662746\teval-logloss:0.672239\n",
      "[22]\ttrain-logloss:0.661754\teval-logloss:0.671479\n",
      "[23]\ttrain-logloss:0.660691\teval-logloss:0.670903\n",
      "[24]\ttrain-logloss:0.659721\teval-logloss:0.670436\n",
      "[25]\ttrain-logloss:0.658731\teval-logloss:0.669782\n",
      "[26]\ttrain-logloss:0.657750\teval-logloss:0.669271\n",
      "[27]\ttrain-logloss:0.656776\teval-logloss:0.668660\n",
      "[28]\ttrain-logloss:0.655622\teval-logloss:0.668143\n",
      "[29]\ttrain-logloss:0.654779\teval-logloss:0.667595\n",
      "[30]\ttrain-logloss:0.653662\teval-logloss:0.666855\n",
      "[31]\ttrain-logloss:0.652844\teval-logloss:0.666216\n",
      "[32]\ttrain-logloss:0.651954\teval-logloss:0.665572\n",
      "[33]\ttrain-logloss:0.651126\teval-logloss:0.665196\n",
      "[34]\ttrain-logloss:0.650349\teval-logloss:0.664798\n",
      "[35]\ttrain-logloss:0.649246\teval-logloss:0.664145\n",
      "[36]\ttrain-logloss:0.648540\teval-logloss:0.663716\n",
      "[37]\ttrain-logloss:0.647661\teval-logloss:0.663224\n",
      "[38]\ttrain-logloss:0.646739\teval-logloss:0.662653\n",
      "[39]\ttrain-logloss:0.645843\teval-logloss:0.662160\n",
      "[40]\ttrain-logloss:0.644908\teval-logloss:0.661599\n",
      "[41]\ttrain-logloss:0.644122\teval-logloss:0.661106\n",
      "[42]\ttrain-logloss:0.643359\teval-logloss:0.660758\n",
      "[43]\ttrain-logloss:0.642523\teval-logloss:0.660393\n",
      "[44]\ttrain-logloss:0.641694\teval-logloss:0.659884\n",
      "[45]\ttrain-logloss:0.640793\teval-logloss:0.659372\n",
      "[46]\ttrain-logloss:0.640026\teval-logloss:0.658934\n",
      "[47]\ttrain-logloss:0.639280\teval-logloss:0.658637\n",
      "[48]\ttrain-logloss:0.638418\teval-logloss:0.658144\n",
      "[49]\ttrain-logloss:0.637545\teval-logloss:0.657845\n",
      "[50]\ttrain-logloss:0.636695\teval-logloss:0.657376\n",
      "[51]\ttrain-logloss:0.635838\teval-logloss:0.656966\n",
      "[52]\ttrain-logloss:0.635270\teval-logloss:0.656469\n",
      "[53]\ttrain-logloss:0.634548\teval-logloss:0.656112\n",
      "[54]\ttrain-logloss:0.633614\teval-logloss:0.655720\n",
      "[55]\ttrain-logloss:0.632808\teval-logloss:0.655229\n",
      "[56]\ttrain-logloss:0.632141\teval-logloss:0.654772\n",
      "[57]\ttrain-logloss:0.631392\teval-logloss:0.654262\n",
      "[58]\ttrain-logloss:0.630626\teval-logloss:0.653896\n",
      "[59]\ttrain-logloss:0.629993\teval-logloss:0.653637\n",
      "[60]\ttrain-logloss:0.629241\teval-logloss:0.653259\n",
      "[61]\ttrain-logloss:0.628546\teval-logloss:0.652947\n",
      "[62]\ttrain-logloss:0.627893\teval-logloss:0.652567\n",
      "[63]\ttrain-logloss:0.627203\teval-logloss:0.652146\n",
      "[64]\ttrain-logloss:0.626451\teval-logloss:0.651731\n",
      "[65]\ttrain-logloss:0.625735\teval-logloss:0.651244\n",
      "[66]\ttrain-logloss:0.625054\teval-logloss:0.651004\n",
      "[67]\ttrain-logloss:0.624480\teval-logloss:0.650765\n",
      "[68]\ttrain-logloss:0.623724\teval-logloss:0.650332\n",
      "[69]\ttrain-logloss:0.623148\teval-logloss:0.650088\n",
      "[70]\ttrain-logloss:0.622332\teval-logloss:0.649691\n",
      "[71]\ttrain-logloss:0.621614\teval-logloss:0.649385\n",
      "[72]\ttrain-logloss:0.620854\teval-logloss:0.649005\n",
      "[73]\ttrain-logloss:0.620221\teval-logloss:0.648632\n",
      "[74]\ttrain-logloss:0.619460\teval-logloss:0.648351\n",
      "[75]\ttrain-logloss:0.618703\teval-logloss:0.648042\n",
      "[76]\ttrain-logloss:0.618117\teval-logloss:0.647760\n",
      "[77]\ttrain-logloss:0.617586\teval-logloss:0.647554\n",
      "[78]\ttrain-logloss:0.616910\teval-logloss:0.647206\n",
      "[79]\ttrain-logloss:0.616322\teval-logloss:0.646811\n",
      "[80]\ttrain-logloss:0.615569\teval-logloss:0.646466\n",
      "[81]\ttrain-logloss:0.614929\teval-logloss:0.646102\n",
      "[82]\ttrain-logloss:0.614296\teval-logloss:0.645691\n",
      "[83]\ttrain-logloss:0.613611\teval-logloss:0.645335\n",
      "[84]\ttrain-logloss:0.613056\teval-logloss:0.645055\n",
      "[85]\ttrain-logloss:0.612451\teval-logloss:0.644818\n",
      "[86]\ttrain-logloss:0.611791\teval-logloss:0.644602\n",
      "[87]\ttrain-logloss:0.611204\teval-logloss:0.644251\n",
      "[88]\ttrain-logloss:0.610628\teval-logloss:0.643960\n",
      "[89]\ttrain-logloss:0.609998\teval-logloss:0.643696\n",
      "[90]\ttrain-logloss:0.609315\teval-logloss:0.643423\n",
      "[91]\ttrain-logloss:0.608705\teval-logloss:0.643173\n",
      "[92]\ttrain-logloss:0.608088\teval-logloss:0.642833\n",
      "[93]\ttrain-logloss:0.607502\teval-logloss:0.642536\n",
      "[94]\ttrain-logloss:0.606883\teval-logloss:0.642177\n",
      "[95]\ttrain-logloss:0.606261\teval-logloss:0.641868\n",
      "[96]\ttrain-logloss:0.605682\teval-logloss:0.641590\n",
      "[97]\ttrain-logloss:0.605067\teval-logloss:0.641361\n",
      "[98]\ttrain-logloss:0.604502\teval-logloss:0.641102\n",
      "[99]\ttrain-logloss:0.603864\teval-logloss:0.640821\n",
      "[100]\ttrain-logloss:0.603262\teval-logloss:0.640488\n",
      "[101]\ttrain-logloss:0.602630\teval-logloss:0.640172\n",
      "[102]\ttrain-logloss:0.602032\teval-logloss:0.639922\n",
      "[103]\ttrain-logloss:0.601478\teval-logloss:0.639624\n",
      "[104]\ttrain-logloss:0.600826\teval-logloss:0.639322\n",
      "[105]\ttrain-logloss:0.600348\teval-logloss:0.639207\n",
      "[106]\ttrain-logloss:0.599710\teval-logloss:0.639062\n",
      "[107]\ttrain-logloss:0.599183\teval-logloss:0.638820\n",
      "[108]\ttrain-logloss:0.598610\teval-logloss:0.638559\n",
      "[109]\ttrain-logloss:0.598049\teval-logloss:0.638353\n",
      "[110]\ttrain-logloss:0.597521\teval-logloss:0.638135\n",
      "[111]\ttrain-logloss:0.596982\teval-logloss:0.637906\n",
      "[112]\ttrain-logloss:0.596443\teval-logloss:0.637692\n",
      "[113]\ttrain-logloss:0.595781\teval-logloss:0.637350\n",
      "[114]\ttrain-logloss:0.595267\teval-logloss:0.637087\n",
      "[115]\ttrain-logloss:0.594600\teval-logloss:0.636894\n",
      "[116]\ttrain-logloss:0.594060\teval-logloss:0.636763\n",
      "[117]\ttrain-logloss:0.593498\teval-logloss:0.636429\n",
      "[118]\ttrain-logloss:0.592971\teval-logloss:0.636206\n",
      "[119]\ttrain-logloss:0.592580\teval-logloss:0.635959\n",
      "[120]\ttrain-logloss:0.591981\teval-logloss:0.635685\n",
      "[121]\ttrain-logloss:0.591448\teval-logloss:0.635459\n",
      "[122]\ttrain-logloss:0.590916\teval-logloss:0.635197\n",
      "[123]\ttrain-logloss:0.590484\teval-logloss:0.635012\n",
      "[124]\ttrain-logloss:0.589970\teval-logloss:0.634795\n",
      "[125]\ttrain-logloss:0.589333\teval-logloss:0.634537\n",
      "[126]\ttrain-logloss:0.588889\teval-logloss:0.634322\n",
      "[127]\ttrain-logloss:0.588323\teval-logloss:0.634023\n",
      "[128]\ttrain-logloss:0.587782\teval-logloss:0.633762\n",
      "[129]\ttrain-logloss:0.587297\teval-logloss:0.633597\n",
      "[130]\ttrain-logloss:0.586747\teval-logloss:0.633415\n",
      "[131]\ttrain-logloss:0.586194\teval-logloss:0.633104\n",
      "[132]\ttrain-logloss:0.585706\teval-logloss:0.632890\n",
      "[133]\ttrain-logloss:0.585298\teval-logloss:0.632721\n",
      "[134]\ttrain-logloss:0.584776\teval-logloss:0.632509\n",
      "[135]\ttrain-logloss:0.584305\teval-logloss:0.632352\n",
      "[136]\ttrain-logloss:0.583745\teval-logloss:0.632215\n",
      "[137]\ttrain-logloss:0.583144\teval-logloss:0.631895\n",
      "[138]\ttrain-logloss:0.582620\teval-logloss:0.631618\n",
      "[139]\ttrain-logloss:0.582123\teval-logloss:0.631452\n",
      "[140]\ttrain-logloss:0.581671\teval-logloss:0.631265\n",
      "[141]\ttrain-logloss:0.581154\teval-logloss:0.630973\n",
      "[142]\ttrain-logloss:0.580781\teval-logloss:0.630790\n",
      "[143]\ttrain-logloss:0.580358\teval-logloss:0.630569\n",
      "[144]\ttrain-logloss:0.579823\teval-logloss:0.630339\n",
      "[145]\ttrain-logloss:0.579306\teval-logloss:0.630088\n",
      "[146]\ttrain-logloss:0.578808\teval-logloss:0.629858\n",
      "[147]\ttrain-logloss:0.578271\teval-logloss:0.629628\n",
      "[148]\ttrain-logloss:0.577783\teval-logloss:0.629370\n",
      "[149]\ttrain-logloss:0.577271\teval-logloss:0.629101\n",
      "[150]\ttrain-logloss:0.576574\teval-logloss:0.628805\n",
      "[151]\ttrain-logloss:0.576011\teval-logloss:0.628609\n",
      "[152]\ttrain-logloss:0.575567\teval-logloss:0.628457\n",
      "[153]\ttrain-logloss:0.575170\teval-logloss:0.628302\n",
      "[154]\ttrain-logloss:0.574751\teval-logloss:0.628112\n",
      "[155]\ttrain-logloss:0.574199\teval-logloss:0.627934\n",
      "[156]\ttrain-logloss:0.573737\teval-logloss:0.627727\n",
      "[157]\ttrain-logloss:0.573165\teval-logloss:0.627496\n",
      "[158]\ttrain-logloss:0.572727\teval-logloss:0.627363\n",
      "[159]\ttrain-logloss:0.572266\teval-logloss:0.627254\n",
      "[160]\ttrain-logloss:0.571935\teval-logloss:0.627180\n",
      "[161]\ttrain-logloss:0.571483\teval-logloss:0.627007\n",
      "[162]\ttrain-logloss:0.571053\teval-logloss:0.626795\n",
      "[163]\ttrain-logloss:0.570596\teval-logloss:0.626663\n",
      "[164]\ttrain-logloss:0.570195\teval-logloss:0.626519\n",
      "[165]\ttrain-logloss:0.569762\teval-logloss:0.626351\n",
      "[166]\ttrain-logloss:0.569258\teval-logloss:0.626078\n",
      "[167]\ttrain-logloss:0.568922\teval-logloss:0.625954\n",
      "[168]\ttrain-logloss:0.568421\teval-logloss:0.625700\n",
      "[169]\ttrain-logloss:0.568002\teval-logloss:0.625565\n",
      "[170]\ttrain-logloss:0.567602\teval-logloss:0.625324\n",
      "[171]\ttrain-logloss:0.567022\teval-logloss:0.625089\n",
      "[172]\ttrain-logloss:0.566526\teval-logloss:0.624876\n",
      "[173]\ttrain-logloss:0.566187\teval-logloss:0.624734\n",
      "[174]\ttrain-logloss:0.565776\teval-logloss:0.624593\n",
      "[175]\ttrain-logloss:0.565316\teval-logloss:0.624400\n",
      "[176]\ttrain-logloss:0.564931\teval-logloss:0.624256\n",
      "[177]\ttrain-logloss:0.564506\teval-logloss:0.624040\n",
      "[178]\ttrain-logloss:0.563985\teval-logloss:0.623879\n",
      "[179]\ttrain-logloss:0.563580\teval-logloss:0.623731\n",
      "[180]\ttrain-logloss:0.563023\teval-logloss:0.623432\n",
      "[181]\ttrain-logloss:0.562456\teval-logloss:0.623119\n",
      "[182]\ttrain-logloss:0.562083\teval-logloss:0.623041\n",
      "[183]\ttrain-logloss:0.561596\teval-logloss:0.622838\n",
      "[184]\ttrain-logloss:0.561285\teval-logloss:0.622657\n",
      "[185]\ttrain-logloss:0.560835\teval-logloss:0.622521\n",
      "[186]\ttrain-logloss:0.560458\teval-logloss:0.622383\n",
      "[187]\ttrain-logloss:0.559959\teval-logloss:0.622283\n",
      "[188]\ttrain-logloss:0.559542\teval-logloss:0.622092\n",
      "[189]\ttrain-logloss:0.559224\teval-logloss:0.622041\n",
      "[190]\ttrain-logloss:0.558819\teval-logloss:0.621952\n",
      "[191]\ttrain-logloss:0.558365\teval-logloss:0.621805\n",
      "[192]\ttrain-logloss:0.557906\teval-logloss:0.621710\n",
      "[193]\ttrain-logloss:0.557701\teval-logloss:0.621638\n",
      "[194]\ttrain-logloss:0.557292\teval-logloss:0.621543\n",
      "[195]\ttrain-logloss:0.556911\teval-logloss:0.621399\n",
      "[196]\ttrain-logloss:0.556399\teval-logloss:0.621269\n",
      "[197]\ttrain-logloss:0.555983\teval-logloss:0.621081\n",
      "[198]\ttrain-logloss:0.555619\teval-logloss:0.620900\n",
      "[199]\ttrain-logloss:0.555200\teval-logloss:0.620713\n",
      "[200]\ttrain-logloss:0.554711\teval-logloss:0.620481\n",
      "[201]\ttrain-logloss:0.554299\teval-logloss:0.620352\n",
      "[202]\ttrain-logloss:0.553892\teval-logloss:0.620201\n",
      "[203]\ttrain-logloss:0.553522\teval-logloss:0.620040\n",
      "[204]\ttrain-logloss:0.553167\teval-logloss:0.619889\n",
      "[205]\ttrain-logloss:0.552889\teval-logloss:0.619814\n",
      "[206]\ttrain-logloss:0.552398\teval-logloss:0.619665\n",
      "[207]\ttrain-logloss:0.551830\teval-logloss:0.619424\n",
      "[208]\ttrain-logloss:0.551479\teval-logloss:0.619264\n",
      "[209]\ttrain-logloss:0.551076\teval-logloss:0.619099\n",
      "[210]\ttrain-logloss:0.550685\teval-logloss:0.618965\n",
      "[211]\ttrain-logloss:0.550255\teval-logloss:0.618766\n",
      "[212]\ttrain-logloss:0.549826\teval-logloss:0.618536\n",
      "[213]\ttrain-logloss:0.549497\teval-logloss:0.618440\n",
      "[214]\ttrain-logloss:0.549137\teval-logloss:0.618343\n",
      "[215]\ttrain-logloss:0.548856\teval-logloss:0.618290\n",
      "[216]\ttrain-logloss:0.548484\teval-logloss:0.618169\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = train_data, label = train_labels)\n",
    "Xdatatest = xgboost.DMatrix(data = test_data, label = test_labels)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.692112\teval-logloss:0.692331\n",
      "[1]\ttrain-logloss:0.690966\teval-logloss:0.691626\n",
      "[2]\ttrain-logloss:0.690063\teval-logloss:0.691127\n",
      "[3]\ttrain-logloss:0.689281\teval-logloss:0.690595\n",
      "[4]\ttrain-logloss:0.688442\teval-logloss:0.690320\n",
      "[5]\ttrain-logloss:0.687842\teval-logloss:0.690062\n",
      "[6]\ttrain-logloss:0.687131\teval-logloss:0.689804\n",
      "[7]\ttrain-logloss:0.686442\teval-logloss:0.689340\n",
      "[8]\ttrain-logloss:0.685796\teval-logloss:0.689001\n",
      "[9]\ttrain-logloss:0.685025\teval-logloss:0.688842\n",
      "[10]\ttrain-logloss:0.684591\teval-logloss:0.688549\n",
      "[11]\ttrain-logloss:0.683832\teval-logloss:0.688139\n",
      "[12]\ttrain-logloss:0.683208\teval-logloss:0.687889\n",
      "[13]\ttrain-logloss:0.682690\teval-logloss:0.687725\n",
      "[14]\ttrain-logloss:0.682203\teval-logloss:0.687506\n",
      "[15]\ttrain-logloss:0.681642\teval-logloss:0.687321\n",
      "[16]\ttrain-logloss:0.680971\teval-logloss:0.686889\n",
      "[17]\ttrain-logloss:0.680593\teval-logloss:0.686738\n",
      "[18]\ttrain-logloss:0.679950\teval-logloss:0.686580\n",
      "[19]\ttrain-logloss:0.679447\teval-logloss:0.686357\n",
      "[20]\ttrain-logloss:0.678993\teval-logloss:0.686151\n",
      "[21]\ttrain-logloss:0.678353\teval-logloss:0.685999\n",
      "[22]\ttrain-logloss:0.677883\teval-logloss:0.685642\n",
      "[23]\ttrain-logloss:0.677332\teval-logloss:0.685410\n",
      "[24]\ttrain-logloss:0.676863\teval-logloss:0.685150\n",
      "[25]\ttrain-logloss:0.676234\teval-logloss:0.684802\n",
      "[26]\ttrain-logloss:0.675761\teval-logloss:0.684461\n",
      "[27]\ttrain-logloss:0.675314\teval-logloss:0.684422\n",
      "[28]\ttrain-logloss:0.674844\teval-logloss:0.684227\n",
      "[29]\ttrain-logloss:0.674487\teval-logloss:0.683993\n",
      "[30]\ttrain-logloss:0.674041\teval-logloss:0.683748\n",
      "[31]\ttrain-logloss:0.673477\teval-logloss:0.683561\n",
      "[32]\ttrain-logloss:0.673063\teval-logloss:0.683557\n",
      "[33]\ttrain-logloss:0.672600\teval-logloss:0.683344\n",
      "[34]\ttrain-logloss:0.672193\teval-logloss:0.683141\n",
      "[35]\ttrain-logloss:0.671793\teval-logloss:0.683090\n",
      "[36]\ttrain-logloss:0.671500\teval-logloss:0.682910\n",
      "[37]\ttrain-logloss:0.671016\teval-logloss:0.682664\n",
      "[38]\ttrain-logloss:0.670509\teval-logloss:0.682513\n",
      "[39]\ttrain-logloss:0.670202\teval-logloss:0.682302\n",
      "[40]\ttrain-logloss:0.669847\teval-logloss:0.682047\n",
      "[41]\ttrain-logloss:0.669432\teval-logloss:0.681984\n",
      "[42]\ttrain-logloss:0.668926\teval-logloss:0.681796\n",
      "[43]\ttrain-logloss:0.668592\teval-logloss:0.681691\n",
      "[44]\ttrain-logloss:0.668165\teval-logloss:0.681510\n",
      "[45]\ttrain-logloss:0.667693\teval-logloss:0.681400\n",
      "[46]\ttrain-logloss:0.667286\teval-logloss:0.681159\n",
      "[47]\ttrain-logloss:0.666920\teval-logloss:0.681049\n",
      "[48]\ttrain-logloss:0.666482\teval-logloss:0.680851\n",
      "[49]\ttrain-logloss:0.666250\teval-logloss:0.680634\n",
      "[50]\ttrain-logloss:0.665874\teval-logloss:0.680352\n",
      "[51]\ttrain-logloss:0.665457\teval-logloss:0.680210\n",
      "[52]\ttrain-logloss:0.665042\teval-logloss:0.680060\n",
      "[53]\ttrain-logloss:0.664666\teval-logloss:0.679954\n",
      "[54]\ttrain-logloss:0.664306\teval-logloss:0.679800\n",
      "[55]\ttrain-logloss:0.663945\teval-logloss:0.679576\n",
      "[56]\ttrain-logloss:0.663589\teval-logloss:0.679582\n",
      "[57]\ttrain-logloss:0.663215\teval-logloss:0.679438\n",
      "[58]\ttrain-logloss:0.662907\teval-logloss:0.679308\n",
      "[59]\ttrain-logloss:0.662541\teval-logloss:0.679311\n",
      "[60]\ttrain-logloss:0.662128\teval-logloss:0.679374\n",
      "[61]\ttrain-logloss:0.661680\teval-logloss:0.679191\n",
      "[62]\ttrain-logloss:0.661311\teval-logloss:0.679098\n",
      "[63]\ttrain-logloss:0.660960\teval-logloss:0.679050\n",
      "[64]\ttrain-logloss:0.660724\teval-logloss:0.678968\n",
      "[65]\ttrain-logloss:0.660354\teval-logloss:0.678640\n",
      "[66]\ttrain-logloss:0.659856\teval-logloss:0.678363\n",
      "[67]\ttrain-logloss:0.659611\teval-logloss:0.678280\n",
      "[68]\ttrain-logloss:0.659330\teval-logloss:0.678058\n",
      "[69]\ttrain-logloss:0.659050\teval-logloss:0.678022\n",
      "[70]\ttrain-logloss:0.658605\teval-logloss:0.677872\n",
      "[71]\ttrain-logloss:0.658225\teval-logloss:0.677652\n",
      "[72]\ttrain-logloss:0.658012\teval-logloss:0.677519\n",
      "[73]\ttrain-logloss:0.657664\teval-logloss:0.677549\n",
      "[74]\ttrain-logloss:0.657279\teval-logloss:0.677464\n",
      "[75]\ttrain-logloss:0.656893\teval-logloss:0.677316\n",
      "[76]\ttrain-logloss:0.656557\teval-logloss:0.677100\n",
      "[77]\ttrain-logloss:0.656278\teval-logloss:0.676970\n",
      "[78]\ttrain-logloss:0.655924\teval-logloss:0.676944\n",
      "[79]\ttrain-logloss:0.655547\teval-logloss:0.676922\n",
      "[80]\ttrain-logloss:0.655209\teval-logloss:0.676656\n",
      "[81]\ttrain-logloss:0.654993\teval-logloss:0.676580\n",
      "[82]\ttrain-logloss:0.654571\teval-logloss:0.676558\n",
      "[83]\ttrain-logloss:0.654323\teval-logloss:0.676466\n",
      "[84]\ttrain-logloss:0.653900\teval-logloss:0.676136\n",
      "[85]\ttrain-logloss:0.653599\teval-logloss:0.675918\n",
      "[86]\ttrain-logloss:0.653267\teval-logloss:0.675829\n",
      "[87]\ttrain-logloss:0.652973\teval-logloss:0.675733\n",
      "[88]\ttrain-logloss:0.652677\teval-logloss:0.675609\n",
      "[89]\ttrain-logloss:0.652466\teval-logloss:0.675506\n",
      "[90]\ttrain-logloss:0.652191\teval-logloss:0.675455\n",
      "[91]\ttrain-logloss:0.651860\teval-logloss:0.675391\n",
      "[92]\ttrain-logloss:0.651558\teval-logloss:0.675309\n",
      "[93]\ttrain-logloss:0.651318\teval-logloss:0.675133\n",
      "[94]\ttrain-logloss:0.650952\teval-logloss:0.675100\n",
      "[95]\ttrain-logloss:0.650704\teval-logloss:0.675060\n",
      "[96]\ttrain-logloss:0.650299\teval-logloss:0.674868\n",
      "[97]\ttrain-logloss:0.650008\teval-logloss:0.674619\n",
      "[98]\ttrain-logloss:0.649709\teval-logloss:0.674444\n",
      "[99]\ttrain-logloss:0.649503\teval-logloss:0.674331\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = X_train, label = y_train)\n",
    "Xdatatest = xgboost.DMatrix(data = X_test, label = y_test)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss alg =  0.637214501074\n",
      "Log_loss bst =  0.674337547331\n"
     ]
    }
   ],
   "source": [
    "alg.fit(X_train, y_train)\n",
    "y_pred_alg = alg.predict_proba(X_test)[:, 1]\n",
    "print \"Log_loss alg = \", log_loss(y_test, y_pred_alg)\n",
    "y_pred_bst = bst.predict(xgboost.DMatrix(X_test))\n",
    "print \"Log_loss bst = \", log_loss(y_test, y_pred_bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss alg =  0.603468642561\n",
      "Log_loss bst =  0.601759704424\n"
     ]
    }
   ],
   "source": [
    "alg.fit(train_data, train_labels)\n",
    "y_pred_alg = alg.predict_proba(test_data)[:, 1]\n",
    "print \"Log_loss alg = \", log_loss(test_labels, y_pred_alg)\n",
    "y_pred_bst = bst.predict(xgboost.DMatrix(test_data))\n",
    "print \"Log_loss bst = \", log_loss(test_labels, y_pred_bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def losses_func(w):\n",
    "    return log_loss(test_labels, (y_pred_alg*w[0] + y_pred_bst*w[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = opt.minimize(losses_func, method='Nelder-Mead', x0=[-1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582819318456\n"
     ]
    }
   ],
   "source": [
    "print x.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_alg_submission = alg.predict_proba(X_test_submission)[:,1]\n",
    "y_test_bst_submission = bst.predict(xgboost.DMatrix(X_test_submission))\n",
    "y_test_submission = y_test_alg_submission*x.x[0] + y_test_bst_submission*x.x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = sample_submission.copy()\n",
    "\n",
    "for i in range(len(y_test_submission)):\n",
    "    c = y_test_submission[i]\n",
    "    if(c <= 0.02):\n",
    "        y_test_submission[i] = 0.0\n",
    "    if(c >= 0.98):\n",
    "        y_test_submission[i] = 1.0\n",
    "        \n",
    "for c in y_test_submission:\n",
    "    if(c < 0 or c>1):\n",
    "        print c\n",
    "        \n",
    "ss.target = y_test_submission\n",
    "ss.to_csv('Double-alg-xgboost-lin_part1', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
